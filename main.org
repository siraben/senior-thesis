#+TITLE: Notions of graph theory in type theory
#+SUBTITLE: A case study on definitional differences between type-theoretic constructions of graphs.
#+AUTHOR: Siraphob (Ben) Phipathananunth
#+LATEX_CLASS: scrartcl
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{bussproofs}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \newtheorem*{thm*}{Theorem}
#+LATEX_HEADER: \newtheorem{thm}{Theorem}
#+LATEX_HEADER: \newtheorem{lem}[thm]{Lemma}
#+LATEX_HEADER: \usepackage[backend=biber]{biblatex}
#+LATEX_HEADER: \addbibresource{citations.bib}

\newcommand{\typ}{\,:\,}
\newcommand{\lam}[2]{\lambda #1.\,#2}
\newcommand{\app}[2]{#1\,#2}
\newcommand{\red}{\to_\beta}
\newcommand{\tred}{\twoheadrightarrow_\beta}

#+BEGIN_abstract
Despite the rich theory and extensive applications of graph theory in
computer science and mathematics, formal developments of graph theory
have mostly been restricted to specific applications or definitions of
graphs. In this work we seek to catalog various approaches to
formalization of graph theory that have been taken in the literature,
in particular, the motivations underlying the formalization, the
theoretical design choices taken and the strength of the conclusions.
#+END_abstract

#+BEGIN_comment
Notes for presentation later:
- interesting thing is that this work involves simultaneously ideas
  from logic, type theory, graph theory and computer science
#+END_comment

#+BEGIN_comment
• Introduction
  • Historical context for logics, formalization of mathematics
• Overview of dependent type theory
  • Comparisons with set theory and first-order theories
  • Curry-Howard correspondence
  • Constructivism and axioms
  • Representation of mathematical objects in type theory
• Overview of graph theory formalizations in Coq
  • math-comp (2008), formalization of four-color theorem
  • CertiGraph (2019), verification of graph-manipulating programs
  • Doczkal and Pous (2019), formalization of Menger’s theorem and treewidths
  • my formalization, verification of graph coloring
• Conclusion
  • Relation to developments in other proof assistants (Lean, Isabelle/HOL)
• Future work
#+END_comment

#+BEGIN_comment
Writing notes:
- do not write too much about type theory since we really want to get
  to writing about *how to define graph theory in type theory*, compare
  the different formalizations, organizing the theories and proof
  engineering
- can always refer reader to other sources (make sure to cite)
#+END_comment

* Introduction

** Notational conventions
To maintain consistent notation throughout the paper, we will use
/italics/ when referencing mathematical objects such as sets and types.
We will use ~monospace~ when referencing definitions in the Coq proof
assistant. This is so we can remain unambiguous when we refer to a
graph /G/, its degree $|G|$ and a Coq statement ~max_degree G > 0~. that
its degree is non-zero.

* Mechanization of mathematics and computer science
The formalist approach to mathematics has had a long history dating
back to Euclid's /Elements/. In such developments, it is desirable to
capture arguments and conclusions drawn from a finite set of axioms
and rules of inference. Proof checking would then be a process that a
mathematician could follow by hand. If the axioms and inferences were
applied correctly, then that is all that is needed to establish the
validity of a result.

However, in recent years, there have been cases where some
mathematical proofs were considered infeasible for a human to verify,
thus bringing into question the validity of the result. For instance,
in 1976, Appel and Haken announced a positive proof of the four-color
problem which was assisted in part by a computer program to perform
the extensive case analysis for the reducible configurations. However,
in the years that followed, several errors were uncovered which were
subsequently fixed. Eventually, in 2005, Gonthier et al. formalized
the result in the Coq proof assistant, eliminating the need for
trusting a program to check the cases.\cite{gonthier}

A similar series of events played out for the proof of the Kepler
Conjecture, which concerns the optimal packing density for spheres in
three dimensions. Hales announced a proof of the Kepler conjecture
involving lengthy case analysis with computer
assistance. Subsequently, with Hales leading the Flyspeck project, a
formal proof of the Kepler conjecture was announced in 2017, using the
Isabelle and HOL Light proof assistants.\cite{hales}

Mechanization can also provide much-needed rigor to areas that contain
many folklore results. In 2021, Forster et al. presented a mechanized
proof of the time invariance thesis for the weak call-by-value
\lambda-calculus, which states that the weak call-by-value
\lambda-calculus and Turing machines can simulate each other with a
polynomial overhead in time.\cite{forster} They provide an account of
prior work on the result and the varying levels of formality in
them. The work has been contributed to the Coq Library of
Undecidability Proofs.

Inspired by these lines of work, we seek to understand, document and
develop mechanized theories of graph theory in Coq. Graph theory is a
particularly suitable area for mechanization due to its wide
applicability across various fields, its simple underlying structure,
and its computability. Graphs are fundamental objects in mathematics
and computer science, with numerous applications in physics, biology,
social sciences, and engineering. They are used to model complex
systems, such as networks of social interactions, transportation
systems, communication networks, and more.

The simplicity of a graph's underlying structure makes them a natural
fit for mechanization. Graphs consist of vertices and edges, which can
be represented as sets, functions or relations (as we shall see,
representation can bring have subtle metatheoretic implications). This
simplicity allows for a clear formalization of the concepts and
definitions of graph theory, and facilitates the automation of
reasoning tasks.

Furthermore, graph algorithms are inherently computable, making them
amenable to computer-assisted proofs. The algorithms for problems such
as finding the shortest path between two vertices, testing for the
existence of a cycle, or determining the chromatic number of a graph,
can be implemented in a computer program and executed to obtain a
solution. This computability enables the use of proof assistants,
which can help verify the correctness of the algorithms and proofs.

* Overview of dependent type theory
Type theory has a rich history, dating back to the work of Bertrand
Russell and Alfred North Whitehead's Principia Mathematica in the
early 20^{th} century.\cite{whitehead} The aim of type theory is to
provide a foundation for mathematics that avoids the paradoxes arising
from naive set theory. In type theory, the objects of interest are not
sets, but rather types and terms over those types.

Simply Typed Lambda Calculus (STLC) is a type theory that was
introduced by Church in the 1940s. It consists of rules of inference
that declare how one may produce valid derivations. The objects of
interest in STLC are terms and types over those terms. When a term $x$
has the type $\tau$, the notational convention is $x:\tau$, which is
analogous to set membership.

The terms are built up from variables, constants, and functions,
according to the following grammar:

\begin{align*}
\textit{Term} \ e & ::= x \mid \lambda x : \tau . e \mid e_1 \ e_2 \\
\textit{Type} \ \tau & ::= \alpha \mid \tau_1 \to \tau_2
\end{align*}

Proof rules are a useful tool in STLC to establish the validity of
type derivations. Here are the inference rules for the three rules in
STLC, along with their names:

\begin{prooftree}
\AxiomC{}
\RightLabel{(Var)}
\UnaryInfC{$\Gamma,x:\tau \vdash x:\tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash e_1 : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash e_2 : \sigma$}
\RightLabel{(App)}
\BinaryInfC{$\Gamma \vdash e_1\,e_2 : \tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma,x:\sigma \vdash e : \tau$}
\RightLabel{(Abs)}
\UnaryInfC{$\Gamma \vdash (\lambda x.e) : \sigma \to \tau$}
\end{prooftree}

The first inference rule is for the variable rule, which states that
if $x$ has type $\tau$ in the context $\Gamma$, then $x$ has type
$\tau$. The second inference rule is for the application rule, which
states that if $e_1$ has type $\sigma \to \tau$ and $e_2$ has type
$\sigma$ in the context $\Gamma$, then $e_1\ e_2$ has type $\tau$. By
convention, application is left-associative and parentheses may be
omitted. The third inference rule is for the lambda abstraction rule,
which states that if $e$ has type $\tau$ in the context $\Gamma$
extended with a variable $x$ of type $\sigma$, then $\lambda x.e$ has
type $\sigma \to \tau$.

Polymorphic lambda calculus extends STLC by introducing type-level
quantifiers, allowing functions to be defined over types. One example
of polymorphic lambda calculus is System F, which adds the ability to
define functions over types. The quantifiers in System F are
type-level, allowing for more expressive type signatures. Here is an
example of an inference rule for the type abstraction rule in System
F:

\begin{prooftree}
\AxiomC{$\Gamma, \alpha \vdash e:\tau$}
\RightLabel{(TAbs)}
\UnaryInfC{$\Gamma \vdash \Lambda \alpha.e:\forall \alpha.\tau$}
\end{prooftree}

This inference rule shows that if expression $e$ has type $\tau$ in
the context $\Gamma$ extended with a type variable $\alpha$, then the
type abstraction $\Lambda \alpha.e$ has the polymorphic type $\forall
\alpha.\tau$.

Dependent type theory extends System F by allowing types to depend on
terms, enabling more expressivity. The Calculus of Constructions is an
example of dependent type theory that adds the ability to define
functions over types, creating a type hierarchy. The Calculus of
Inductive Constructions extends the Calculus of Constructions with
inductive types, allowing for formalization of mathematical structures
such as natural numbers, lists, and trees.

In the Calculus of Constructions, a key feature is the use of
universes, which are a hierarchy of types that can contain other
types. A universe is a type that can serve as the type of other types,
and universes can contain each other in a hierarchy. For example, the
universe of small types might be contained within a larger universe of
larger types.

Universes are necessary in the Calculus of Constructions because they
allow us to avoid paradoxes that arise when types are allowed to
contain themselves. By separating types into a hierarchy of universes,
we can ensure that any given type is contained in a universe that is
larger than itself, preventing paradoxes such as Russell's paradox.

Here is an example of a proof rule for the dependent product formation
rule in the Calculus of Constructions:

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \typ U_i$}
\AxiomC{$\Gamma, x:A \vdash B \typ U_j$}
\RightLabel{(Prod)}
\BinaryInfC{$\Gamma \vdash (\Pi x:A.B) \typ U_{\max(i,j)}$}
\end{prooftree}

This inference rule shows that if $A$ has type $U_i$ and $B$ has type
$U_j$ in the context $\Gamma$ extended with variable $x$ of type $A$,
then the dependent product $\Pi x:A.B$ has type $U_{\max(i,j)}$. More
information about universes can be found in \cite{ttfp}.

Dependent type theory provides a foundation for modern proof
assistants such as Coq and Lean, which use the Calculus of Inductive
Constructions as their underlying logic. These proof assistants are
used to formalize mathematics, verify software, and prove the
correctness of algorithms.

** Computation in type theory
The calculi presented so far resembles a Hilbert-style calculus, we
have only considered proof trees that derive well-typed terms. What
distinguishes type theory from other logical calculi is the
/computational behavior/ of the terms. Formally, there is a binary
/evaluation relation/ (often denoted as $\to_\beta$) over the terms. In
the \lambda-calculus, $\to_\beta$ is defined as follows:

\begin{align*}
(\lambda x.f) e &\to_\beta e[f/x]
\end{align*}

Here, $[f/x]$ denotes the substitution of $f$ for free occurrences of
$x$ in $e$. The reflexive transitive closure of $\beta$ is denoted as
$\tred$.

Various results exist regarding $\tred$, most notably strong
normalization in typed \lambda-calculi, including for STLC:

\begin{thm*}
For all expressions $e$ of the Simply Typed Lambda Calculus, all reduction sequences beginning with $e$ are finite.
\end{thm*}

A proof can be found in \cite{ttfp}.

The existence of the untyped calculus is briefly mentioned here. This
is the calculus generated by the \lambda-calculus without any type
restrictions. It is worth noting that strong normalization does not
hold for the untyped calculus, as reduction sequences can be
infinite. However, the untyped calculus still plays a significant role
in the study of \lambda-calculus and its various properties, such as
the Church-Rosser theorem, which states that if a term can be reduced
to two different normal forms, there exists a common reduct for both
of them.

In the context of type theory, the computation rules, such as the
evaluation relation $\to_\beta$, are crucial for connecting the
logical aspects of the type theory with its computational aspects. For
instance, these rules can be used to model the operational semantics
of programming languages and enable the extraction of executable code
from formal proofs. Moreover, the properties of these computation
rules, such as strong normalization, can provide insights into the
decidability and termination of programs and algorithms.

** Curry-Howard correspondence

The Curry-Howard correspondence provides a correspondence between
proof calculi and computational type systems. In propositional logic,
a formula consists of either a propositional variable $X_n$ or a
compound formula $A \land B$, $A \lor B$, $A \implies B$, $\lnot A$,
where $A$ and $B$ are formulas. The Curry-Howard correspondence
provides a way to map these logical formulas to types and lambda terms
in a computational type system. The table below summarizes the
correspondence between logic, types, and sets.

| *Logic*                | *Types*              | *Sets*                          |
|----------------------+--------------------+-------------------------------|
| proposition          | $A$                | set                           |
| proof                | $a : A$            | element                       |
| predicate            | $B(x)$             | family of sets                |
| conditional proof    | $b(x): B(x)$       | family of elements            |
| $\bot,\top$          | 0,1                | $\varnothing,\{\varnothing\}$ |
| $A\lor B$            | $A + B$            | disjoint union                |
| $A\land B$           | $A \times B$       | cartesian product             |
| $A\implies B$        | $A \to B$          | set of functions              |
| $\exists_{x:A} B(x)$ | $\sum_{x:A} B(x)$  | disjoint union of families    |
| $\forall_{x:A} B(x)$ | $\prod_{x:A} B(x)$ | cartesian product of families |

For STLC, the Curry-Howard correspondence can be viewed as a theorem
that relates the derivation of any judgement
$x_1:A_1,\ldots,x_n:A_n\vdash B$ with a lambda term $M$ such that
$x_1:A_1,\ldots,x_n:A_n\vdash M : B$ is a valid typing judgement. In
other words, each valid proof in propositional logic corresponds to a
valid lambda term in the simply-typed lambda calculus, and vice versa.

** Constructing new types in type theory
In type theory, it is possible to introduce new types by either
defining them as inductive types or by defining them as dependent
types. The ability to construct new types is a fundamental aspect of
type theory that enables the encoding of complex mathematical
structures.

In STLC, only base types and function types can be defined. Base types
are fixed by the language, while function types are constructed using
the arrow operator $\to$. For example, the type of a function that
takes an integer as input and returns a boolean as output can be
written as $int \to bool$.

In System F, polymorphic types can be defined using universal
quantification. For example, the identity function can be defined with
type $\forall \alpha. \alpha \to \alpha$, where $\alpha$ is a type
variable ranging over all possible types. This type captures the
essence of the identity function, which takes any input of any type
and returns the same value.

In the Calculus of Constructions, new types can be defined using
dependent products, dependent sums, and inductive types. A dependent
product is a type of the form $\prod_{x:A} B(x)$, where $A$ is a type
and $B : A \to \mathbb{U}$ is a type that depends on $x$. This type
can be interpreted as the type of functions that take an input of type
$A$ and return an output of type $B(x)$ for some $x$. For example, the
dependent product $\prod_{n:\mathbb{N}}\mathbb{R}^n$ represents the
type of functions that take an input $n$ representing the dimension of
a vector and return an output of type $\mathbb{R}^n$ representing a
vector in \(n\)-dimensional space. Note that if $B : A \to \mathbb{U}$
is a constant function, the dependent product $\prod_{x:A} B(x)$ is
the same as the function type $A \to B$.

A dependent sum is a type of the form $\sum_{x:A} B(x)$, where $A$ is
a type and $B(x)$ is a type that depends on $x$. This type can be
interpreted as the type of pairs $(a,b)$ where $a$ is an element of
type $A$ and $b$ is an element of type $B(a)$. For example, the
dependent sum $\sum_{n:\mathbb{N}}\mathbb{R}^n$ represents the type of
pairs $(n,v)$ where $n$ is a natural number representing the dimension
of a vector and $v$ is an element of type $\mathbb{R}^n$ representing
a vector in \(n\)-dimensional space.

Inductive types allow for the construction of new types using
constructors that create new elements of the type. For example, the
natural numbers can be defined as an inductive type with constructors
$0$ and $succ(n)$, where $n$ is a natural number. The type of natural
numbers can be written as $Nat$, and elements of this type can be
constructed using the constructors $0$ and $succ(n)$.

** Inductive Types in the Calculus of Constructions
Inductive types are a powerful feature in the Calculus of
Constructions, enabling the definition of complex mathematical
structures such as natural numbers, lists, and trees. In Coq, one of
the most popular proof assistants based on the Calculus of
Constructions, inductive types are defined using the ~Inductive~ keyword
followed by the name of the type and its constructors.

For example, the natural numbers can be defined in Coq as follows:

#+BEGIN_SRC coq
Inductive nat : Type :=
| O : nat
| S : nat -> nat.
#+END_SRC

This definition introduces a new type nat with two constructors O and
S, representing zero and successor, respectively. The constructor S
takes an argument of type nat and returns a new nat representing its
successor.

Lists can also be defined as an inductive type in Coq, with two
constructors ~nil~ and ~cons~ representing the empty list and the cons
operation, respectively:

#+BEGIN_SRC coq
Inductive list (A : Type) : Type :=
| nil : list A
| cons : A -> list A -> list A.
#+END_SRC

This definition introduces a new type list A parameterized over a type
A, with two constructors nil and cons. The constructor cons takes an
element of type A and a list of type list A, and returns a new list
with the element added to the front.

Here is an example of a Coq function that computes the length of a list:

#+BEGIN_SRC coq
Fixpoint length {A : Type} (l : list A) : nat :=
match l with
| nil => O
| cons _ xs => S (length xs)
end.
#+END_SRC

This function uses pattern matching to match on the two constructors
nil and cons, and recursively computes the length of the rest of the
list using the length function.

In the Calculus of Constructions, inductive types are defined using a
similar syntax, with constructors specified using the \(C : T\)
notation where \(C\) is the constructor name and \(T\) is the type of
the constructor.

Here is the definition of the natural numbers as an inductive type in
the Calculus of Constructions:

*Formation Rule for* $\mathbb{N}$

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\vdash \mathbb{N} : \mathbb{U}$}
\end{prooftree}

*Introduction Rules for* $\mathbb{N}$
\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\vdash 0 : \mathbb{N}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\vdash n : \mathbb{N}$}
\UnaryInfC{$\vdash \texttt{succ}\,n : \mathbb{N}$}
\end{prooftree}

This definition introduces a new inductive type nat with two
constructors 0 and /succ/, and is a type that belongs to the universe.

# talk about monotonicity constraint on type operators and fixpoints?

** Comparisons with Set Theory and First-order Theories
Dependent type theory provides several advantages over these classical
systems. Unlike in set theory, which is primarily based on the notion
of collections of elements, dependent type theory revolves around the
concept of types and their inhabitants. This allows for a more natural
way of reasoning about mathematical objects and their properties.

In first-order theories, quantifiers range over elements of a single
sort, whereas in dependent type theory, it is possible for different
quantifiers in the same formula to refer to elements of different
types. This allows for a more flexible and expressive way of
expressing mathematical concepts and reasoning about them.

# In summary, dependent type theory provides a powerful foundation for
# mathematics and computer science, enabling precise and expressive
# reasoning about mathematical objects and their properties. It is a
# foundation for modern proof assistants such as Coq, Lean, and Agda,
# which are used to formalize mathematics, verify software, and prove
# the correctness of algorithms.

# introduction to dep TT, history, etc.
** Interactions between axioms in dependent type theory
In particular, we must take care when adding extra assumptions in type
theory, since they may interact in subtle ways that allow for LEM to
be proven. For instance, assuming propositional extensionality and
decidable equality implies LEM:

\begin{thm*}
Propositional extensionality (PropExt) and decidable equality
(DecEq) together imply LEM.
\end{thm*}

# use proof environment
\begin{proof}
Assume PropExt, that is, for all propositions $P$, $Q$,
$P\leftrightarrow Q$ implies $P=Q$. Assume DecEq, that is, for all
types $X$ and members $a$, $b$ of type $X$, either $a=b$ or $a\neq b$.

First we prove a small lemma that for all propositions $P$,
$P=(P=\top)$. That is, a proposition $P$ is equal to a proof of
equality between $P$ and $\top$, which has a single trivial
inhabitant. By PropExt, it suffices to prove
$P\leftrightarrow (P=\top)$.

$(\Rightarrow)$ Assume $P$. We want to show $P=\top$. By PropExt,
it suffices to show $P\leftrightarrow\top$, which is trivial because
we have a proof of $P$ and the trivial proof for $\top$.

$(\Leftarrow)$ Assume $P=\top$. We want to show $P$. This is trivial
since using the assumption we have to prove $\top$.

Now, assume DecEq and PropExt and fix an arbitrary proposition
$P$. From DecEq we have that $P = \top \vee P \neq\top$. This is
equivalent to $P=\top\vee((P=\top)\to\bot)$. From the lemma we have
$P\vee(P\to\bot)$ thus we have $P\vee\neg P$, thus $P$ is decided.
\end{proof}

For completeness, we demonstrate how the 

#+CAPTION: Formal Coq proof of Lemma 1.
#+BEGIN_src coq
Definition eq_prop := forall (P Q : Prop), (P <-> Q) -> P = Q.
Definition dec_eq := forall (X : Type) (a b : X), a = b \/ a <> b.
Definition lem := forall (P : Prop), P \/ ~ P.

(* The small lemma *)
Lemma small_lemma : forall (P : Prop), eq_prop -> P = (P = True).
Proof.
  intros P eq_prop.
  apply eq_prop.
  split; intros.
  - apply eq_prop; firstorder.
  - rewrite H; firstorder.
Qed.

(* LEM follows from eq_prop and dec_eq *)
Lemma eq_prop_deceq_lem : eq_prop -> dec_eq -> lem.
Proof.
  unfold dec_eq, lem.
  intros eq_prop dec_eq P.
  rewrite (small_lemma P).
  - apply dec_eq.
  - apply eq_prop.
Qed.
#+END_src

*We want to keep the logic constructive.* The interested reader may
refer to \cite{bauer}.


* Overview of Coq
Coq\cite{coqart} is a proof assistant for writing mathematical
statements, constructing their proofs and mechanically checking the
validity of their proofs. The logical foundation of Coq is the
Calculus of Inductive Constructions. There are many resources and
guides on various aspects of Coq applied in different contexts, such
as program verification or mechanization of
mathematics.\cite{cpdt}\cite{sergey}

Coq consists of two languages, \textit{Gallina} and
\textit{Ltac}. Gallina is the specification language of Coq and can be
thought of as the expressions in Coq. Gallina is purely functional and
has support for dependent types and dependent pattern
matching. \textit{Ltac} is the tactic language of Coq and is what is
used to carry out formal proofs. An introduction can be found in
\cite{tactic} and \cite{hurry}. It suffices to say that, from a
usability standpoint, \textit{Ltac} commands operate on the current
\textit{proof state}, which is the context consisting of hypothesis
and a goal. The commands may introduce new hypotheses, clear existing
ones, allow application of one hypothesis to another, discriminate a
value in context, and so on.

** Definitions

** Interactive proofs

** Curry-Howard Correspondence revisited

** Proof Engineering
In the last few decades, the practice of /proof engineering/ has emerged
whereby formal developments are carried out and maintained at
scale. Many proof engineering techniques take inspiration from work in
software engineering.\cite{klein2014proof} An extensive survey can be
found in \cite{ringer2019qed}. Although the logical foundations of
proof assistants are for the most part fixed, the practices and
conventions surrounding the development of theories is constantly in
flux.

* Building graph theory in Coq
It is one thing to 


# When building any mathematical theory, one must start with the
# definition of the objects of that theory.

# - graph theory is usually built on top of set theory
# - but we're in type theory
# - example of decidable equality

** Example lemma: maximum degree and subgraphs
To illustrate the level of detail that is required in a formal proof
and to motivate introspection into implicit assumptions about graphs,
we will deconstruct a lemma about how maximum degrees interact with
the subgraph relation.

*Lemma.* Let ~G'~ be a subgraph of ~G~. Then ~max_deg G' <= max_deg G~.

*Proof.* When ~max_deg G'~ is zero, this is immediate. Otherwise, there is
some vertex ~k~ of non-zero maximum degree in ~G'~. Since ~G'~ is a subgraph
of ~G~, this vertex ~k~ is also in ~G~. Since ~G'~ is a subgraph of ~G~, the
pointwise vertex sets of ~G'~ are subsets of the corresponding vertex
set in ~G~. In particular, ~G'[k]~ is a subset of ~G[k]~. Let ~t~ be the
vertex of (non-zero) maximum degree in ~G~. Since ~t~ is a vertex of
maximum degree, the size of ~G[t]~ bounds the size of all other vertex
sets, in particular ~G[k]~. Thus, ~max_deg G' = G'[k] <= G[k] <= G[t] =
max_deg G~, as desired.

* Survey of graph theory developments in Coq
** Mathematical Components
# cite 4color theorem
The arguably most well-known formalization of graph theory in a proof
assistant can be seen in Gonthier's formal proof of the Four-Color
Theorem.


# expand
In the literature, graph theory has been successfully implemented in
Coq and has lead to formalizations of major theorems such as the four
color theorem. Other results include formalization of Ramsey
theorems, max-flow min-cut for countable graphs.

# cite Graph Theory in Coq: Minors, Treewidth and Isomorphisms
Doczkal and Pous develop graph theory in Coq to reason about minors,
treewidth and isomorphisms.\cite{doczkal}

However, many assumptions underlie the graph structure used in formal
developments. For instance, it is often assumed that the vertex type
is finite and the edge relation is decidable.

These are reasonable assumptions.

The assumptions that underlie such formal developments

** CertiGraph
# Certifying graph-manipulating C programs via localizations within
# data structures
Wang et al. develops mechanized graph theory as a necessary component
of being able to reason about graph-manipulating programs written in
CompCert C, a dialect of the C programming language that has a
verified compiler (i.e. the preservation of the semantics of the
source and compiled programs is formally stated and proved). To the
author's knowledge, this is one of the most comprehensive general
development of graph theory in Coq to date.\cite{wang}

# cite Wang thesis: Mechanized Verification of Graph-Manipulating
# Programs
In Wang 2019, particular attention was paid to the definition of
graphs in order to retain as much generality as possible. The base
construction of the graph is as follows:

#+begin_src coq
Definition Ensemble (U : Type) := U -> Prop.
Record PreGraph (Vertex Edge : Type)
                {EV: EqDec Vertex eq} {EE: EqDec Edge eq} := {
  vvalid : Ensemble Vertex;
  evalid : Ensemble Edge;
  src : Edge -> Vertex;
  dst : Edge -> Vertex
}.
#+end_src

That is, we start with a notion of a ~PreGraph~, which is a record
parameterized over types ~Vertex~ and ~Edge~ (corresponding to the types
for vertices and edges respectively), along with proofs of decidable
equality over those types.  As we have seen in a previous section,
decidable equality for types is not guaranteed in the same way it is
for set theory.  In the context of graph-manipulating programs, Wang
states that decidable equality ``is such a fundamental property that
almost all sensible graph-manipulating algorithms employ it whether or
not they realize it''.

# continue talking about Wang's construction of graphs in type theory

\newpage
\printbibliography
