#+TITLE: Formalizing graph theory in type theory
#+AUTHOR: Siraphob (Ben) Phipathananunth
#+OPTIONS: toc:nil
#+LATEX_CLASS: scrartcl
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{bussproofs}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{coqdoc}
#+LATEX_HEADER: \usepackage{algpseudocode,algorithm,algorithmicx}
#+LATEX_HEADER: \newtheorem*{thm*}{Theorem}
#+LATEX_HEADER: \newtheorem{thm}{Theorem}
#+LATEX_HEADER: \newtheorem*{lem}{Lemma}
#+LATEX_HEADER: \usepackage[backend=biber]{biblatex}
#+LATEX_HEADER: \addbibresource{citations.bib}

\newcommand{\typ}{\,:\,}
\newcommand{\lam}[2]{\lambda #1.\,#2}
\newcommand{\app}[2]{#1\,#2}
\newcommand{\red}{\to_\beta}
\newcommand{\tred}{\twoheadrightarrow_\beta}

#+BEGIN_abstract
Despite the rich theory and extensive applications of graph theory in
computer science and mathematics, formal developments of graph theory
have mostly been restricted to specific applications or definitions of
graphs. In this work we present progress towards formalization of
Wigderson's graph coloring algorithm through our own novel
approach. We also provide a comprehensive review of various
formalization approaches found in the literature, examining their
motivations, theoretical design choices, and the robustness of their
conclusions.
#+END_abstract

#+BEGIN_comment
Notes for presentation later:
- interesting thing is that this work involves simultaneously ideas
  from logic, type theory, graph theory and computer science
#+END_comment

#+BEGIN_comment
• Introduction
  • Historical context for logics, formalization of mathematics
• Overview of dependent type theory
  • Comparisons with set theory and first-order theories
  • Curry-Howard correspondence
  • Constructivism and axioms
  • Representation of mathematical objects in type theory
• Overview of graph theory formalizations in Coq
  • math-comp (2008), formalization of four-color theorem
  • CertiGraph (2019), verification of graph-manipulating programs
  • Doczkal and Pous (2019), formalization of Menger’s theorem and treewidths
  • my formalization, verification of graph coloring
• Conclusion
  • Relation to developments in other proof assistants (Lean, Isabelle/HOL)
• Future work
#+END_comment

#+BEGIN_comment
Writing notes:
- do not write too much about type theory since we really want to get
  to writing about *how to define graph theory in type theory*, compare
  the different formalizations, organizing the theories and proof
  engineering
- can always refer reader to other sources (make sure to cite)
#+END_comment
\tableofcontents
\newpage
* Introduction
The formalist approach to mathematics has had a long history dating
back to Euclid's /Elements/. In this approach, it is desirable to
capture arguments and conclusions drawn from a finite set of axioms
and rules of inference. Proof checking would then become a process
that a mathematician could follow by hand. If the axioms and
inferences were applied correctly, then that is all that is needed to
establish the validity of a result.

However, in recent years, there have been cases where some
mathematical proofs were considered infeasible for a human to verify,
thus bringing into question the validity of the result. For instance,
in 1976, Appel and Haken announced a proof of the four-color problem
which was assisted in part by a computer program to perform the
extensive case analysis for the reducible configurations. However, in
the years that followed, several errors were uncovered which were
corrected. Eventually, in 2005, Gonthier et al. formalized the result
in the Coq proof assistant, eliminating the need for trusting a
program to check the cases.\cite{gonthier}

A similar series of events played out for the proof of the Kepler
Conjecture, which concerns the optimal packing density for spheres in
three dimensions. Hales announced a proof of the Kepler conjecture
that involved lengthy case analysis with computer
assistance. Subsequently, with Hales leading the Flyspeck project, a
formal proof of the Kepler conjecture was announced in 2017, using the
Isabelle and HOL Light proof assistants.\cite{hales}

Mechanization can also provide much-needed rigor to areas that contain
many folklore results. Forster et al., in 2021, presented a mechanized
proof of the time invariance thesis for the weak call-by-value
\lambda-calculus, which states that the weak call-by-value
\lambda-calculus and Turing machines can simulate each other with a
polynomial overhead in time.\cite{forster} They provide an account of
prior work on the result and the varying levels of formality in
them. The work has been contributed to the Coq Library of
Undecidability Proofs.

Inspired by these lines of work, we seek to understand, document and
develop mechanized theories of graph theory in Coq. Graph theory is a
particularly suitable area for mechanization due to its wide
applicability across various fields, its simple underlying structure,
and its computability. Graphs are fundamental objects in mathematics
and computer science, with numerous applications in physics, biology,
social sciences, and engineering. They are used to model complex
systems, such as networks of social interactions, transportation
systems, communication networks, and more.

The simplicity of a graph's underlying structure makes them a natural
fit for mechanization. Graphs consist of vertices and edges, which can
be represented as sets, functions, or relations. However, as we shall
see, the choice of representation can have subtle metatheoretic
implications.

Graph algorithms are inherently computable, making them amenable to
computer-assisted proofs. The algorithms for problems such as finding
the shortest path between two vertices, testing for the existence of a
cycle, or determining the chromatic number of a graph, can be
implemented in a computer program and executed to obtain a
solution. This computability enables the use of proof assistants,
which can help verify the correctness of the algorithms and proofs.

For our main formalization effort, we choose Wigderson's graph
coloring algorithm. This is a relatively simple algorithm that will
motivate much of our work. Furthermore, graph coloring algorithms have
important applications in scheduling problems, wireless communication,
and register allocation in compilers. Thus, progress towards a
reusable theory of graph coloring will contribute to opening up other
avenues for future research.

* Overview of dependent type theory
Type theory has a rich history, dating back to Principia Mathematica
by Russell and Whitehead in the early 20^{th} century.\cite{whitehead}
The aim of type theory is to provide a foundation for mathematics that
avoids the paradoxes arising from naive set theory. In type theory,
the objects of interest are not sets, but rather types and terms over
those types.

Simply Typed Lambda Calculus (STLC) is a type theory that was
introduced by Church in the 1940s. It consists of rules of inference
that declare how one may produce valid derivations. The objects of
interest in STLC are terms and types over those terms. When a term $x$
has the type $\tau$, the notational convention is $x:\tau$, which is
analogous to set membership.

The terms are built up from variables, constants, and functions,
according to the following grammar:

\begin{align*}
\textit{Term} \ e & ::= x \mid \lambda x : \tau . e \mid e_1 \ e_2 \\
\textit{Type} \ \tau & ::= \alpha \mid \tau_1 \to \tau_2
\end{align*}

Proof rules are a useful tool in STLC to establish the validity of
type derivations. Here are the inference rules for the three rules in
STLC, along with their names:

\begin{prooftree}
\AxiomC{}
\RightLabel{(Var)}
\UnaryInfC{$\Gamma,x:\tau \vdash x:\tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash e_1 : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash e_2 : \sigma$}
\RightLabel{(App)}
\BinaryInfC{$\Gamma \vdash e_1\,e_2 : \tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma,x:\sigma \vdash e : \tau$}
\RightLabel{(Abs)}
\UnaryInfC{$\Gamma \vdash (\lambda x.e) : \sigma \to \tau$}
\end{prooftree}

The first inference rule is for the variable rule, which states that
if $x$ has type $\tau$ in the context $\Gamma$, then $x$ has type
$\tau$. The second inference rule is for the application rule, which
states that if $e_1$ has type $\sigma \to \tau$ and $e_2$ has type
$\sigma$ in the context $\Gamma$, then $e_1\ e_2$ has type $\tau$. By
convention, application is left-associative and parentheses may be
omitted. The third inference rule is for the lambda abstraction rule,
which states that if $e$ has type $\tau$ in the context $\Gamma$
extended with a variable $x$ of type $\sigma$, then $\lambda x.e$ has
type $\sigma \to \tau$.

Polymorphic \lambda-calculus extends STLC by introducing type-level
quantifiers, allowing functions to be defined over types. One example
of a polymorphic \lambda-calculus is System F, which adds the ability
to define functions over types. The quantifiers in System F are
type-level, allowing for more expressive type signatures. Here is an
example of an inference rule for the type abstraction rule in System
F:

\begin{prooftree}
\AxiomC{$\Gamma, \alpha \vdash e:\tau$}
\RightLabel{(TAbs)}
\UnaryInfC{$\Gamma \vdash \Lambda \alpha.e:\forall \alpha.\tau$}
\end{prooftree}

This inference rule shows that if expression $e$ has type $\tau$ in
the context $\Gamma$ extended with a type variable $\alpha$, then the
type abstraction $\Lambda \alpha.e$ has the polymorphic type $\forall
\alpha.\tau$.

Dependent type theory extends System F by allowing types to depend on
terms, enabling greater expressiveness. The Calculus of Constructions
is an example of dependent type theory that adds the ability to define
functions over types, creating a type hierarchy. The Calculus of
Inductive Constructions extends the Calculus of Constructions with
inductive types, allowing for formalization of mathematical structures
such as natural numbers, lists, and trees.

In the Calculus of Constructions, a key feature is the use of
universes, which are a hierarchy of types that can contain other
types. A universe is a type that can serve as the type of other types,
and universes can contain each other in a hierarchy. For example, the
universe of small types might be contained within a larger universe of
larger types.

Universes are necessary in the Calculus of Constructions because they
allow us to avoid paradoxes that arise when types are allowed to
contain themselves. By separating types into a hierarchy of universes,
we can ensure that any given type is contained in a universe that is
larger than itself, preventing paradoxes such as Girard's paradox
(the type-theoretic analog of Russell's paradox.)\cite{girard_paradox}

Here is an example of a proof rule for the dependent product formation
rule in the Calculus of Constructions:

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \typ \mathbb{U}_i$}
\AxiomC{$\Gamma, x:A \vdash B \typ \mathbb{U}_j$}
\RightLabel{(Prod)}
\BinaryInfC{$\Gamma \vdash (\Pi x:A.B) \typ \mathbb{U}_{\max(i,j)}$}
\end{prooftree}

This inference rule shows that if $A$ has type $\mathbb{U}_i$ and $B$
has type $\mathbb{U}_j$ in the context $\Gamma$ extended with variable
$x$ of type $A$, then the dependent product $\Pi x:A.B$ has type
$\mathbb{U}_{\max(i,j)}$. More information about universes can be
found in \cite{ttfp}. An extension to the Predicative Calculus of
Inductive Constructions can be found in \cite{cumulative}.

Dependent type theory provides a foundation for modern proof
assistants such as Coq and Lean, which use the Calculus of Inductive
Constructions as their underlying logic. These proof assistants are
used to formalize mathematics, verify software, and prove the
correctness of algorithms.

** Computation in type theory
The calculi presented so far resembles a Hilbert-style calculus, we
have only considered proof trees that derive well-typed terms. What
distinguishes type theory from other logical calculi is the
computational behavior of the terms. Formally, there is a binary
/evaluation relation/ (often denoted as $\to_\beta$) over the terms. In
the \lambda-calculus, $\to_\beta$ is defined as follows:

\begin{align*}
(\lambda x.f) e &\to_\beta e[f/x]
\end{align*}

Here, $[f/x]$ denotes the substitution of $f$ for free occurrences of
$x$ in $e$. The reflexive transitive closure of $\to_\beta$ is denoted as
$\tred$. Various results exist regarding $\tred$, most notably strong
normalization in typed \lambda-calculi, including for STLC:

\begin{thm*}[Strong Normalization]
For all expressions $e$ of the Simply Typed Lambda Calculus, all reduction sequences beginning with $e$ are finite.
\end{thm*}

A proof of strong normalization and other results can be found in
\cite{ttfp}.

The existence of the untyped calculus is briefly mentioned here. This
is the calculus generated by the syntax without any type
restrictions. Strong normalization does not hold for the untyped
calculus, as reduction sequences can be infinite (consider the
expression $(\lambda x.(x x)) (\lambda x.(x x))$). However, the untyped
calculus still plays a significant role in the study of
\lambda-calculus and its various properties, such as the Church-Rosser
theorem, which states that if a term can be reduced to two different
normal forms, there exists a common reduct for both of them.

In the context of type theory, the computation rules, such as the
evaluation relation $\to_\beta$, are crucial for connecting the
logical aspects of the type theory with its computational aspects. For
instance, these rules can be used to model the operational semantics
of programming languages and enable the extraction of executable code
from formal proofs. Moreover, the properties of these computation
rules, such as strong normalization, can provide insights into the
decidability and termination of programs and algorithms.

** Curry-Howard correspondence
The Curry-Howard correspondence provides a correspondence between
proof calculi and computational type systems.\cite{wadler} In
propositional logic, a formula consists of either a propositional
variable $X_n$ or a compound formula $A \land B$, $A \lor B$, $A
\implies B$, $\lnot A$, where $A$ and $B$ are formulas. The
Curry-Howard correspondence provides a way to map propositional
formulas to types and lambda terms in a computational type system. The
table below summarizes the correspondence between logic, types, and
sets.

| *Logic*                | *Types*              | *Sets*                          |
|----------------------+--------------------+-------------------------------|
| proposition          | $A$                | set                           |
| proof                | $a : A$            | element                       |
| predicate            | $B(x)$             | family of sets                |
| conditional proof    | $b(x): B(x)$       | family of elements            |
| $\bot,\top$          | 0,1                | $\varnothing,\{\varnothing\}$ |
| $A\lor B$            | $A + B$            | disjoint union                |
| $A\land B$           | $A \times B$       | cartesian product             |
| $A\implies B$        | $A \to B$          | set of functions              |
| $\exists_{x:A} B(x)$ | $\sum_{x:A} B(x)$  | disjoint union of families    |
| $\forall_{x:A} B(x)$ | $\prod_{x:A} B(x)$ | cartesian product of families |

For STLC, the Curry-Howard correspondence can be viewed as a theorem
that relates the derivation of any judgement
$x_1:A_1,\ldots,x_n:A_n\vdash B$ with a lambda term $M$ such that
$x_1:A_1,\ldots,x_n:A_n\vdash M : B$ is a valid typing judgement. In
other words, each valid proof in propositional logic corresponds to a
valid lambda term in STLC, and vice versa.

The Curry-Howard correspondence also occurs at the level of proofs and
programs. Further details can be read in \cite{ttfp} and
\cite{wadler}.

| *Logic*                    | *Types*                  |
|--------------------------+------------------------|
| undischarged assumptions | free variables         |
| discharged assumptions   | bound variables        |
| simplification of proofs | evaluation of programs |


** Constructing new types in type theory
In type theory, it is possible to introduce new types by either
defining them as inductive types or as dependent types. The ability to
construct new types is a fundamental aspect of type theory that
enables the encoding of complex mathematical structures.

In STLC, only base types and function types can be defined. Base types
are fixed by the language, while function types are constructed using
the arrow operator, $\to$. For example, the type of a function that
takes an integer as input and returns a boolean as output can be
written as $int \to bool$.

In System F, polymorphic types can be defined using universal
quantification. For example, the identity function can be defined with
type $\forall \alpha. \alpha \to \alpha$, where $\alpha$ is a type
variable ranging over all possible types. This type captures the
essence of the identity function, which takes an input of any type and
returns the same value.

In the Calculus of Constructions, new types can be defined using
dependent products, dependent sums, and inductive types. A dependent
product is a type of the form $\prod_{x:A} B(x)$, where $A$ is a type
and $B : A \to \mathbb{U}$ is a type that depends on $x$. This type
can be interpreted as the type of functions that take an input of type
$A$ and return an output of type $B(x)$ for some $x$. For example, the
dependent product $\prod_{n:\mathbb{N}}\mathbb{R}^n$ represents the
type of functions that take an input $n$ representing the dimension of
a vector and return an output of type $\mathbb{R}^n$ representing a
vector in \(n\)-dimensional space. Note that if $B : A \to \mathbb{U}$
is a constant function, the dependent product $\prod_{x:A} B(x)$ is
the same as the function type, $A \to B$.

A dependent sum is a type of the form $\sum_{x:A} B(x)$, where $A$ is
a type and $B(x)$ is a type that depends on $x$. This type can be
interpreted as the type of pairs $(a,b)$ where $a$ is an element of
type $A$ and $b$ is an element of type $B(a)$. For example, the
dependent sum $\sum_{n:\mathbb{N}}\mathbb{R}^n$ represents the type of
pairs $(n,v)$ where $n$ is a natural number representing the dimension
of a vector and $v$ is an element of type $\mathbb{R}^n$ representing
a vector in \(n\)-dimensional space.


** Inductive types in the Calculus of Constructions
Inductive types allow for the construction of new types using
constructors that create new elements of the type. For example, the
natural numbers can be defined as an inductive type with constructors
$0$ and $succ$. Formally,

*Formation Rule for* $\mathbb{N}$
\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\mathbb{N} : \mathbb{U}$}
\end{prooftree}

*Introduction Rules for* $\mathbb{N}$
\begin{prooftree}
\AxiomC{}
\UnaryInfC{$0 : \mathbb{N}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$n : \mathbb{N}$}
\UnaryInfC{$succ\,n : \mathbb{N}$}
\end{prooftree}

This definition introduces a new inductive type $\mathbb{N}$ with two
constructors 0 and /succ/, and is a type that belongs to the universe.
In terms of metatheory, when we construct an inductive type, we are
taking the fixpoint of a monotonic operation on types $\Theta :
\mathbb{U}\to\mathbb{U}$. Relevant details may be found in Section
7.10 of \cite{ttfp}.

** Equality in dependent type theory
Although the dependent type theory presented so far seems
inexpressive, we can begin to introduce predicates of interest. We
only show a simple example but for full details refer to \cite{ttfp}.

We would like to define propositional equality, to make the logical
assertion regarding two terms $a$ and $b$ as:

\begin{center}
`$a$ and $b$ are equal elements of the type $A$'
\end{center}

In order to do this, we need to introduce a new type $I$ that can
represent the equality of two elements of a given type. We can define
$I$ as follows:

*Formation Rule for* $I$
\begin{prooftree}
\AxiomC{$A : \mathbb{U}$}
\AxiomC{$a : A$}
\AxiomC{$b : A$}
\TrinaryInfC{$I(A,a,b) : \mathbb{U}$}
\end{prooftree}

*Introduction Rule for* $I$
\begin{prooftree}
\AxiomC{$A : \mathbb{U}$}
\AxiomC{$a : A$}
\BinaryInfC{$\text{refl}\,A\,a : I(A,a,a)$}
\end{prooftree}

The formation rule states that $I$ is parameterized by a type $A$ and
two elements $a$ and $b$ of type $A$. The introduction rule states
that for all types $A$ and elements $a$ of type $A$, there is a proof
that $a$ is equal to itself. The following result allows us to use
this definition of propositional equality to rewrite terms that have
a proof of equality between them.

\begin{thm*}
Leibnitz's law is derivable. That is, if we have a type $P(a)$ that
depends on $a$ and $c : I(A,a,b)$, then we can conclude $P(b)$.
\end{thm*}

A proof of this theorem can be found in \cite{ttfp}. Note that this is
different from definitional equality, where convertible or terms that
are equivalent under evaluation may be substituted freely within the
type theory.


** Interactions between axioms in dependent type theory
Under the Curry-Howard correspondence, disjunction corresponds to sum
types. We are also able to define the empty type $\bot$ corresponding
to the always false statement. Thus we can consider the type $\forall
(P : \mathbb{U}),\, P\vee\neg P$. If this type were inhabited, it would
imply a way of selecting an element from every nonempty
type.\cite{hott} For a particular $P$, it is possible to write a term
that yields a proof of $P$ or its negation, but this is not assumed to
be given in general.

In dependent type theory, we must take care when adding extra
assumptions, since they may interact in subtle ways that allow for LEM
to be proven. For instance, assuming propositional extensionality and
decidable equality implies LEM:

\begin{thm*}
Propositional extensionality (PropExt) and decidable equality
(DecEq) together imply LEM.
\end{thm*}

\begin{proof}
Assume PropExt, that is, for all propositions $P$, $Q$,
$P\leftrightarrow Q$ implies $P=Q$. Assume DecEq, that is, for all
types $X$ and members $a$, $b$ of type $X$, either $a=b$ or $a\neq b$.

First we prove a small lemma that for all propositions $P$,
$P=(P=\top)$. That is, a proposition $P$ is equal to a proof of
equality between $P$ and $\top$, which has a single trivial
inhabitant. By PropExt, it suffices to prove
$P\leftrightarrow (P=\top)$.

$(\Rightarrow)$ Assume $P$. We want to show $P=\top$. By PropExt,
it suffices to show $P\leftrightarrow\top$, which is trivial because
we have a proof of $P$ and the trivial proof for $\top$.

$(\Leftarrow)$ Assume $P=\top$. We want to show $P$. This is trivial
since using the assumption we have to prove $\top$.

Now, assume DecEq and PropExt and fix an arbitrary proposition
$P$. From DecEq we have that $P = \top \vee P \neq\top$. This is
equivalent to $P=\top\vee((P=\top)\to\bot)$. From the lemma we have
$P\vee(P\to\bot)$ thus we have $P\vee\neg P$, thus $P$ is decided.
\end{proof}

For completeness, Listing [[fig:coq_proof_lem1]] shows the formal proof of
this theorem in Coq. For more discussion regarding the subtleties of
LEM and its implications for mathematical results when not assumed,
see \cite{bauer}.

#+CAPTION: Formal Coq proof of LEM from PropExt and DecEq.
#+NAME: fig:coq_proof_lem1
#+BEGIN_src coq
Definition prop_ext := forall (P Q : Prop), (P <-> Q) -> P = Q.
Definition dec_eq := forall (X : Type) (a b : X), a = b \/ a <> b.
Definition lem := forall (P : Prop), P \/ ~ P.

Lemma small_lemma : forall (P : Prop), prop_ext -> P = (P = True).
Proof.
  intros P prop_ext.
  apply prop_ext.
  split; intros; [apply prop_ext|rewrite H]; firstorder.
Qed.

(* LEM follows from prop_ext and dec_eq *)
Lemma prop_ext_deceq_lem : prop_ext -> dec_eq -> lem.
Proof.
  unfold dec_eq, lem.
  intros prop_ext dec_eq P.
  rewrite (small_lemma P); [apply dec_eq|apply prop_ext].
Qed.
#+END_src

* Overview of Coq
Coq\cite{coqart} is a proof assistant for writing mathematical
statements, constructing their proofs and mechanically checking the
validity of their proofs. The logical foundation of Coq is the
Calculus of Inductive Constructions. There are many resources and
guides on various aspects of Coq applied in different contexts, such
as program verification or mechanization of
mathematics.\cite{cpdt}\cite{sergey}\cite{sf}

Coq consists of two languages, /Gallina/ and /Ltac/. Gallina is the
specification language of Coq and can be thought of as the underlying
term language. Gallina is purely functional and has support for
dependent types and dependent pattern matching. /Ltac/ is the tactic
language of Coq and is what is used to carry out formal proofs. An
introduction to Ltac and Coq can be found in \cite{tactic} and
\cite{hurry} respectively. It suffices to say that, from a usability
standpoint, \textit{Ltac} commands operate on the current
\textit{proof state}, which is the context consisting of hypotheses
and a goal. The commands may introduce new hypotheses, clear existing
ones, allow application of one hypothesis to another, discriminate a
value in context, and so on.

** Definitions
Inductive types are defined using the ~Inductive~ keyword followed by
the name of the type and its constructors.

For example, the natural numbers can be defined in Coq as follows:

#+BEGIN_SRC coq
Inductive nat : Type :=
| O : nat
| S : nat -> nat.
#+END_SRC

This definition introduces a new type nat with two constructors ~O~ and
~S~, representing zero and successor, respectively. The constructor ~S~
takes an argument of type ~nat~ and returns a new ~nat~ representing its
successor.

Lists can also be defined as an inductive type in Coq, with two
constructors ~nil~ and ~cons~ representing the empty list and the cons
operation, respectively:

#+BEGIN_SRC coq
Inductive list (A : Type) : Type :=
| nil : list A
| cons : A -> list A -> list A.
#+END_SRC

This definition introduces a new list type parameterized over a type
~A~, with two constructors ~nil~ and ~cons~. The constructor ~cons~ takes an
element of type ~A~ and a list of type ~list A~, and returns a new list
with the element added to the front.

Here is an example of a Coq function that computes the length of a
list recursively:

#+BEGIN_SRC coq
Fixpoint length {A : Type} (l : list A) : nat :=
match l with
| nil => O
| cons _ xs => S (length xs)
end.
#+END_SRC

** Writing proofs: tactics and proof terms
Tactics are Ltac commands used to manipulate the proof state in order
to construct a proof term for a given goal. The proof term is an
expression in the Gallina language that, when constructed correctly,
will establish the validity of the goal. As the user applies tactics
to the proof state, Coq builds up a proof term incrementally. Once the
proof term is complete and the proof state is solved, the proof is
considered complete.

Here is an overview of some common tactics in Coq:

- ~intros~: introduce variables and assumptions from the goal into the
  context. It moves premises from the goal into the hypothesis context
  and binds variables as needed.
- ~apply~: used to apply a given hypothesis or lemma to the current
  goal. If the applied hypothesis or lemma matches the goal or part of
  the goal, Coq will generate new subgoals for any premises that have
  not been satisfied.
- ~rewrite~: rewrite the goal or a hypothesis using a given equality. It
  can be used with the ~->~ or ~<-~ symbols to rewrite from left to right
  or right to left, respectively.
- ~simpl~: simplify the goal by performing beta-reduction,
  delta-reduction, and other simplification steps on the current goal.
- ~induction~: perform induction on a given variable, which can be
  helpful when proving properties about inductive types.
- ~destruct~: perform case analysis on a given variable, splitting the
  proof state into cases based on the constructors of the inductive
  type.

Here is an example of a simple proof in Coq using tactics:

#+BEGIN_SRC coq
Theorem add_0_r : forall n : nat, n + 0 = n.
Proof.
  intros n.             (* Introduce the variable n *)
  induction n as [|n']. (* Perform induction on n *)
  - simpl.              (* Base case: simplify *)
    reflexivity.        (* Prove 0 + 0 = 0 *)
  - simpl.              (* Inductive case: simplify *)
    rewrite IHn'.       (* Rewrite using induction hypothesis *)
    reflexivity.        (* Prove (S n') + 0 = S n' *)
Qed.
#+END_SRC

We obtain the following proof term.

#+BEGIN_SRC coq
add_0_r =
    fun n : nat =>
    nat_ind (fun n0 : nat => n0 + 0 = n0) eq_refl
      (fun (n' : nat) (IHn' : n' + 0 = n') =>
       eq_ind_r (fun n0 : nat => S n0 = S n') eq_refl IHn') n
         : forall n : nat, n + 0 = n
#+END_SRC

Where the types of ~nat_ind~, ~eq_refl,~ and ~eq_ind_r~ are as follows:

#+BEGIN_SRC coq
nat_ind : forall P : nat -> Prop,
  P 0 -> (forall n : nat, P n -> P (S n)) ->
  forall n : nat, P n

eq_refl : forall (A : Type) (x : A), x = x

eq_ind_r : forall (A : Type) (x : A) (P : A -> Type) (p : P x),
    forall y : A, x = y -> P y
#+END_SRC

~nat_ind~ is the induction principle for the ~nat~ type. ~eq_refl~ is the
proof of reflexivity for equality. ~eq_ind_r~ allows us to rewrite a
proof term using an equality. As outlined in Section [[Curry-Howard
correspondence]], the under the Curry-Howard correspondence,
well-typed terms correspond to proofs. From a usability perspective,
the user is more concerned about the state of their proof and what
tactic to perform next, as they construct the underlying term.

** Proof engineering
In the last few decades, the practice of /proof engineering/ has emerged
whereby formal developments are carried out and maintained at
scale. Many proof engineering techniques take inspiration from work in
software engineering.\cite{klein2014proof} An extensive survey can be
found in \cite{ringer2019qed}. Although the logical foundations of
proof assistants are for the most part fixed, the practices and
conventions surrounding the development of theories are constantly in
flux.  As proof engineering techniques mature and evolve, they can
greatly enhance the efficiency and maintainability of large-scale
formal developments. Some important aspects of proof engineering
include:

/Modularization/: Organizing formal developments into smaller,
self-contained modules can make proofs more manageable and
understandable. This can involve structuring theories in a
hierarchical manner, using namespaces, and creating reusable
libraries.

/Automation/: Developing custom tactics and decision procedures can
greatly reduce the manual effort required to carry out
proofs. Automation can also help to manage complexity and improve the
overall efficiency of the proof process.

/Documentation/: Providing clear documentation for formal developments
is crucial to ensure that the intended meaning of definitions,
theorems, and proofs is well understood. This includes writing
informative comments, using meaningful naming conventions, and
providing high-level overviews of the proof structure.

/Proof refactoring/: As in software engineering, refactoring proofs can
help to improve their maintainability, readability, and
performance. This may involve simplifying complex proofs, generalizing
specific results, or even changing the underlying definitions to make
them more amenable to formal reasoning.

* Building graph theory in Coq
In this section, we will present how we carried out our own
development of graph theory in Coq. Section [[Survey of graph theory
developments in Coq]] will provide comparison as to how the design
choices here fit in the formalization landscape. The full repository
containing the definitions and proofs can be found in
\cite{wigderson-siraben}. We also provide a printout of the source for
the theory of subgraphs in Section [[Appendix A: A formal theory of
subgraphs]].


** Preliminary definitions
We use the definition of graphs as defined in Volume 3 of \cite{sf} as
a starting point. Listing [[fig:coq_graph_def]] shows the preliminary
definitions of the development. We choose to have vertices be
represented as positive integers, and choose an adjacency set
representation. That is, a graph ~G~ is a finite map from positive
integers to sets of positive integers, representing vertices and their
adjacent vertices respectively.

#+CAPTION: Definition of graphs in Coq.
#+NAME: fig:coq_graph_def
#+BEGIN_SRC coq
Module E := PositiveOrderedTypeBits.
Module S <: FSetInterface.S := PositiveSet.
Module M <: FMapInterface.S := PositiveMap.

Definition node := E.t.
Definition nodeset := S.t.
Definition nodemap: Type -> Type := M.t.
Definition graph := nodemap nodeset.

Definition adj (g: graph) (i: node) : nodeset :=
  match M.find i g with Some a => a | None => S.empty end.

Definition undirected (g: graph) :=
   forall i j, S.In j (adj g i) -> S.In i (adj g j).

Definition no_selfloop (g: graph) := forall i, ~ S.In i (adj g i).

Definition nodes (g: graph) := Mdomain g.
#+END_SRC

The ~adj~ function takes a graph, a vertex and returns a ~nodeset~ (which
is empty if the vertex is not in the graph). The ~undirected~ predicate
states that a graph is undirected if for every pair of vertices ~i~ and
~j~, if ~j~ is in ~i~'s adjacency set then ~i~ is in ~j~'s adjacency
set. ~no_selfloop~ states that a graph is irreflexive if ~i~ is never
contained in its own vertex set. Finally, ~nodes~ takes the
representation of the graph and extracts the key entries
(resp. vertices) of the graph.

For the rest of the development, we will present it backwards from
formalizing a graph coloring algorithm so as to show the process of
how we started with a high-level theorem and worked to find
appropriate lemmas and structures.

* Formalizing Wigderson's algorithm
Our main contribution is progress towards the formalization of key
lemmas for the proof of correctness of Wigderson's
algorithm. Wigderson's algorithm\cite{wigderson} is an approximate
graph coloring algorithm that aims to color a 3-colorable graph
with at most $3\sqrt{n}$ colors in polynomial time. If the graph is
not 3-colorable, then either a valid approximation is returned or the
a certification that the input was not 3-colorable.

Our development will closely follow the paper by
Wigderson\cite{wigderson} in which he presents a proof of correctness
with the given color bound and its polynomial running time, with
appropriate lemmas. First we present an imperative version of the
algorithm then its purely functional equivalent. Then we explore in
detail key lemmas and theories that must be built up for us to reason
about correctness of the algorithm.

The idea of Wigderson's algorithm is to find vertices with degree of
least \(k\). Finding these high-degree vertices allows us to color
more vertices at once since we are able to 2-color the neighborhood
for each of these vertices. Then we remove the colored vertices and
continue this until no such high-degree vertices remain. Then color
the remaining vertices with new colors. Then the pseudocode algorithm
he is as follows where $\Delta(G)$ is the maximum degree of any vertex
in $G$:

#+CAPTION: Wigderson's 3-coloring algorithm.
#+BEGIN_algorithm
\hspace*{\algorithmicindent}\textbf{Input:} A 3-colorable graph $G(V, E)$
\begin{algorithmic}[1]
\State $n \gets |V|$
\State $i \gets 1$
\While {$\Delta(G) \geq k$}
\State $H \gets$ the subgraph of $G$ induced by the neighborhood $N_G(v)$
\State 2-color $H$ with colors $i, i+1$
\State color $v$ with color $i + 2$.
\State $i \gets i + 2$
\State $G \gets$ the subgraph of $G$ resulting from it by deleting $N_G(v) \cup \{v\}$
\EndWhile
\State color $G$ with colors $i, i + 1, i + 2, \dots, \Delta (G)$ and halt
\end{algorithmic}
#+END_algorithm

** Informal proof of correctness
In a 3-colorable graph, the neighborhood of any vertex must consist of
one or both of the two other colors, so the neighborhood of that
vertex is 2-colorable. We can find a 2-coloring easily in linear time
by recursively forcing colors. We do this for vertices with higher
degrees to eliminate as many colors as possible. Finally, we color the
remaining vertices in a straightforward manner.

In the while loop, $i$ is incremented by $2$ and $3$ colors are
used. This means there will be overlap between the final color used on
the current iteration and the first color used on the next
iteration. This is possible since the final color assigned on each
iteration is to $v$. Since the neighborhood of $v$, $N_G(v)$ was
already colored, reusing this color for other vertices will not cause
any contradictions. To make verification easier, we fix the color of
high-degree to color 1 on every iteration and use two unique colors
for the neighborhoods.

** Finding a bound on the number of colors used
Let $n$ be the number of vertices in the graph. In a dense graph, it
is possible that all vertices have at least degree \(k\). However,
each iteration removes at least $k + 1$ vertices from the graph. We
can remove at most $n$ vertices, so $(k+1)x \leq n$ where $x$ is the
number of iterations, and thus $x \leq \frac{n}{k+1}$. Once the loop
terminates, $\Delta(G) < k$, so we can use a polynomial time algorithm
to color these vertices using at most $1 + \Delta(G) < 1 + k$
colors. Therefore, we use at most \(k\) colors to color these
vertices. This gives an upper bound of $k + \frac{2n}{k}$ colors used
since there are $2$ new colors used each iteration. We want to balance
these two terms by selecting an appropriate \(k\) as follows

\begin{align*}
    k &= \frac{2n}{k} \\
    k^2 &= 2n \\
    k &= \sqrt{2n}
\end{align*}

This leads to a bound of $\sqrt{2n} + \frac{2n}{\sqrt{2n}} =
2\sqrt{2n} = \sqrt{8}\sqrt{n} \approx 2.828\sqrt{n} =
O(\sqrt{n})$. For sake of simplicity, we will use $k = \sqrt{n}$ as
Wigderson did. This will give us a bound of $\sqrt{n} +
\frac{2n}{\sqrt{n}} = 3\sqrt{n} = O(\sqrt{n})$. This proves the bound.

** Translation to a functional algorithm
We aim to further detail the algorithm steps to convert this into a
functional program for use in Coq. We use the updated color assignment
process we described and use the value $k = \sqrt{n}$. The algorithm
can be described in two phases: the first where we color the
high-degree vertices and their neighborhoods, and the second is
coloring the remaining vertices. We present the pseudocode for both
Phase I and Phase II of the algorithm, with each phase divided into
further subroutines.

\begin{algorithm}
\caption{Phase I Algorithm}
\hspace*{\algorithmicindent}\textbf{Input:} A graph $G(V, E)$ with $|V| = n$
\begin{algorithmic}[1]
\Function{two-color-vertex}{$v, c_1, c_2$}
  \State Color $v$ with color $c_1$
  \If{$v$ has any uncolored neighbors}
    \State \Call{two-color-vertex}{$x, c_2, c_1$} for all uncolored neighbors $x$ of $v$
  \EndIf
  \State \Return new coloring of $G$
\EndFunction
\Function{two-color-neighborhood}{coloring $f$ of $N$}
  \If{there exists an uncolored vertex in $f$}
    \State $v \gets$ the first uncolored vertex from $f$
    \State $f \gets$ \Call{two-color-vertex}{$v, c_1, c_2$}
    \State \Call{two-color-neighborhood}{$f$}
  \EndIf
  \State \Return $f$
\EndFunction
\Function{phase-1}{graph $G(V, E)$}
  \State $f \gets$ empty coloring
  \If{there exists a vertex with degree at least $\sqrt{n}$}
    \State $v \gets$ first vertex with degree at least $\sqrt{n}$
    \State $f \gets$ $f$ with $v$ assigned color $1$
    \State $f \gets$ \Call{two-color-neighborhood}{$f$}
    \State $G \gets G - (v \cup N_G(v))$
    \State $f, G \gets$ \Call{phase-1}{$G$}
  \EndIf
  \State \Return $f, G$
\EndFunction
\State \Return \Call{phase-1}{$G$}
\end{algorithmic}
\end{algorithm}

In Phase I, the first function 2-colors the connected components of a
vertex. It arbitrarily selects a color and colors the adjacent
vertices, then arbitrarily selects another color for the next
connected component when necessary. The next function applies this to
the whole neighborhood of a vertex. Finally, the Phase I function
selects high-degree vertices and colors them and their neighborhoods
until there are no more high-degree vertices remaining. This leaves us
with a graph with no high degree vertex in which we will then use for
Phase II.

\begin{algorithm}
\caption{Phase II Algorithm}
\hspace*{\algorithmicindent}\textbf{Input:} A graph $G(V, E)$ with maximum degree $d$
\begin{algorithmic}[1]
\Function{color-d}{$G, d, c, f$}
  \If{there exists a vertex with degree $d$}
    \State $v \gets$ first vertex with degree $d$ in $G$
    \State $f \gets f$ with color $c$ assigned to $v$
    \State remove $v$ from $G$
    \State \Return \Call{color-d}{$G, d, c, f$}
  \EndIf
  \State \Return $G$
\EndFunction
\Function{color-all-d}{$G, d, f$, colors $c_0, c_2, \dots, c_d$}
  \If{$d \geq 0$}
    \State $G \gets$ \Call{color-d}{$G, d, c_d, f$}
    \State \Return \Call{color-all-d}{$G, d-1, f, c_0, \dots, c_{d-1}$}
  \EndIf
  \State \Return $G, f$
\EndFunction
\State \Return \Call{color-all-d}{$G, d, f, c_0, \dots, c_d$}
\end{algorithmic}
\end{algorithm}

In Phase II, the goal is to color the remaining graph with $d+1$
colors where $d$ is the maximum degree of the graph. The first
function removes non-adjacent vertices with degree $d$ and assigns
them the same color. The second function simply applies this for all
degrees from $d$ down to $0$ which will fully color the graph with
$d+1$ colors.

** Understanding correctness and robustness
We will now present the informal proofs of correctness to help us
translate these ideas formally into Coq. In the Phase I algorithm, we
attempt to 2-color each neighborhood of high-degree vertices. For a
2-colorable graph, the 2-coloring function will work since we are
simply forcing the choices logically. If this 2-coloring fails, then
the neighborhood is not two colorable, and by the lemma, this means
the graph is not 3-colorable. In this case, we simply return this as a
certificate that the input graph was not 3-colorable. The color of the
high-degree vertex will be assigned color $1$. For the next
high-degree vertex, each of its neighbors cannot be a high-degree
vertex already used since this would mean the vertex would have been
colored. Thus, we can reuse the color $1$. Each step uses $\sqrt{n}$
new vertices, so this means there are at most $\frac{n}{\sqrt{n}} =
\sqrt{n}$ iterations. This means there are $2\sqrt{n} + 1$ colors in
this process. Since the loop terminates when there are no more
vertices of at least degree $\sqrt{n}$, we know that after this
process the uncolored vertices will have degree less than $\sqrt{n}$
i.e. maximum degree is at most $\sqrt{n} - 1$. The final process
simply requires assigning different colors for each degree. Since we
can assign the same color to each vertex in a 1-colorable graph, Phase
II will work by induction. If we assume the process will succeed for
$d-1$ and produce a \(d\)-coloring, then we remove each vertex with
degree $d$. We cannot remove two neighboring vertices since the degree
of the neighbors will decrease by 1 once remove. Therefore, we can use
this color added to the \(d\)-coloring to form a $d+1$ coloring as
desired. This gives us a total of $3\sqrt{n} + 1$ colors (reusing a
color in the final step, we obtain $3\sqrt{n}$).


** Constructing the formalization
Now that we have established context, we continue with the
formalization, as shown in Listing [[fig:coloring_formal]]. A ~coloring~ is
defined to be a finite map from vertices to colors. ~coloring_ok~ states
that for a given palette of colors, graph, and coloring, the coloring
is considered to be OK if for every edge ~i~ to ~j~, if ~i~ is assigned some
color, the color must be in the palette, and the colors of ~j~ and ~i~ (if
they are both colored) are not the same. Note that this allows our
colorings to be partial. ~coloring_complete~ states that for a given
palette of colors, a graph and a coloring, every vertex in the graph
is assigned some color and the entire graph is OK with respect to the
coloring. Finally, ~n_coloring~ states that a given coloring is an
~n~-coloring if the cardinality of the set of colors used is ~n~ and all
vertices that are colored are assigned some color in the palette
(again allowing for partial colorings). The reason why we want to
split the definitions up in this way is that we may need different
conditions at different stages of developments. When we are coloring a
graph, the coloring constructed so far is not a complete coloring;
thus we must allow ourselves to talk about partial colorings that are
consistent thus far. Of course, the definition of ~n_coloring~ makes it
easy to define what a 3-coloring is, and we define ~three_coloring~ for
convenience. The full development may be found in the ~coloring.v~ file
in \cite{wigderson-siraben}.

A key component of Wigderson's algorithm is coloring the neighborhood
of vertices of a given degree. This means that we must be able to
reason about the degree of an arbitrary vertex, its neighborhood, how
we construct the coloring, and so on. We start by building a theory of
subgraphs. The theory of subgraphs ends up being the bulk of our
development, and we provide a full listing of all the lemmas
formalized in Section [[Appendix A: A formal theory of
subgraphs]]. Listing [[fig:subgraph_formal]] shows the key formalization
of subgraphs used in our development. ~g'~ is a subgraph of ~g~ if the
vertex set of ~g'~ is a subset of the vertex set of ~g~ and if the
adjacency set of any ~v~ in ~g'~ is a subset of the adjacency set of ~v~ in
~g~. The ~neighbors~ of ~v~ in ~g~ is simply its adjacency set. To remove a
vertex ~v~ from a graph ~g~, we remove the vertex and its adjacency set
from the graph, then go through all the adjacency sets of all the
vertices and remove ~v~ from them. To induce a subgraph of ~g~ from a
vertex set ~s~, we start with an empty graph. For each vertex ~v~ and its
adjacency set ~adj~, we check if ~v~ is a member of ~s~; if so, we add it
and the intersection of its adjacency set in ~g~ to the new graph.

Finally, the ~neighborhood~ of ~v~ in ~g~ is the result of inducing a
subgraph of ~g~ from its neighbors and then removing ~v~ from the
resulting subgraph.

#+CAPTION: Definitions for coloring in Coq.
#+NAME: fig:coloring_formal
#+BEGIN_SRC coq
Definition colors := S.t.
Definition coloring := M.t node.

Definition coloring_ok (palette: colors) (g: graph) (f: coloring) :=
 forall i j, S.In j (adj g i) ->
     (forall ci, M.find i f = Some ci -> S.In ci palette) /\
     (forall ci cj, M.find i f = Some ci -> M.find j f = Some cj -> ci<>cj).


Definition coloring_complete (palette: colors) (g: graph) (f: coloring) :=
  (forall i, M.In i g -> M.In i f) /\ coloring_ok palette g f.

Definition n_coloring (f : coloring) (p : colors) (n : nat) :=
  S.cardinal p = n /\ forall v c, M.find v f = Some c -> S.In c p.

Definition three_coloring (f : coloring) p := n_coloring f p 3.
#+END_SRC

#+CAPTION: Definitions for subgraphs in Coq.
#+NAME: fig:subgraph_formal
#+BEGIN_SRC coq
Definition is_subgraph (g' g : graph) :=
  S.Subset (nodes g') (nodes g) /\ forall v, S.Subset (adj g' v) (adj g v).

Definition neighbors (g : graph) v := adj g v.

Definition remove_node (v: node) (g: graph) : graph :=
  M.map (S.remove v) (M.remove v g).

Definition subgraph_of (g : graph) (s : S.t) :=
  M.fold (fun v adj g' => if S.mem v s then M.add v (S.inter s adj) g' else g')
         g
         empty_graph.

Definition neighborhood (g : graph) v :=
  remove_node v (subgraph_of g (neighbors g v)).
#+END_SRC
\newpage
** Phase I Lemmas
First, we want to establish that the neighborhood of a vertex in a
3-colorable graph is 2-colorable. Although this may seem simple, due
to the definition of a mapping, this is quite challenging. We first
show that a 3-colorable neighborhood and vertex ~v~ will induce a
3-coloring that only uses 2 colors. We need to show that this coloring
can be transformed into a 2-coloring. Even though the coloring does
not change, the information at the type level changes; we go from
~coloring_complete p g f~ to ~coloring_complete (S.remove ci p)
(neighborhood g v) (restrict_on_nbd f g v)~, meaning we can use the
fact that ~f~ is uses one less color and that it is a complete coloring
on the neighborhood. Below is a more general statement of this lemma.

\begin{lem}
    The subgraph formed by the neighborhood of a vertex in a $n$-colorable graph is $(n-1)$-colorable.
    \begin{proof}
        Let $G$ be a $n$-colorable graph and let $v$ be an arbitrary vertex in $G$. Then there exists a coloring of $G$ using at most $n$ different colors. Vertex $v$ must be assigned some color $c$. Then all vertices adjacent to $v$ i.e. the neighborhood of $v$ will have colors different than $c$. Since the graph is $n$-colorable, one of these being $c$, the neighborhood can only use at most $n-1$ colors.
    \end{proof}
\end{lem}

The formal statement of this lemma appears in in Listing
[[fig:nbd_Sn_formal]]. It reads: for any graph ~g~, coloring ~f~, set of
colors ~p~, and natural number ~n~, if the coloring ~d~ is complete on ~g~
using colors ~p~, and ~f~ is a coloring that uses $n + 1$ colors, then for
any vertex ~v~ with color ~ci~, if we restrict ~f~ to the neighborhood on ~v~
and the result is an ~n~-coloring using the colors
$\texttt{p}\setminus\{\texttt{ci}\}$, then this restricted coloring is
complete on the neighborhood.

#+CAPTION: Formal statement of a lemma on \((n+1)\)-colorability
#+LABEL: fig:nbd_Sn_formal
#+BEGIN_SRC coq
Lemma nbd_Sn_colorable_n :
  forall (g : graph) (f : coloring) (p : colors) (n : nat),
   coloring_complete p g f ->
   n_coloring f p (S n) ->
   forall v ci, M.find v f = Some ci ->
           n_coloring (restrict_on_nbd f g v) (S.remove ci p) n
        /\ coloring_complete (S.remove ci p)
                             (neighborhood g v)
                             (restrict_on_nbd f g v).
#+END_SRC

In this example, it is evident that a formal elaboration of a
statement makes explicit what was implicit before. The coloring ~f~ was
not mentioned in the original statement at all. However, when we
mention that a graph is \((n+1)\)-colorable then make a claim about
the colorability of one of its subgraphs (the neighborhood of ~v~), we
are often referring to the same coloring, or some other coloring
derived from it. Explicitly, the new coloring on the neighborhood is a
restriction of the original coloring, and the palette is now different
since the neighborhood of a vertex does not include the vertex itself.
The formal proof of this lemma may be found in
\cite{wigderson-siraben}. The overall structure of the formal proof
follows the informal one.

We also show the contrapositive of this statement (this is immediate
since $A\to B$ implies $\neg B\to \neg A$ constructively). This shows
that if the neighborhood is not colorable, then the graph is not
3-colorable. We can use this later to show that if our 2-coloring
algorithm fails, then the graph is not 3-colorable. This allows us to
avoid using the 2-coloring given to us by Coq in showing that the
2-coloring function is valid. This will further enable us to prove
robustness of the algorithm.

This lemma enables us to 2-color the neighborhood of any vertex in a
3-colorable graph. We also require additional lemmas for Phase I of
the algorithm. We need to show that removing a high degree vertex
reduces the size of the graph by 1, and that removing its neighborhood
reduces the size of the graph by at least $\sqrt K$.

We also want to show that high-degree vertex selected will not be
adjacent to each other. This implies that each neighborhood we select
is entirely disjoint. This will also imply that we can remove
$\sqrt{K}$ new vertices at each step. We show that this means the
process will terminate and leave the remaining graph with maximum
degree $\sqrt{K}-1$.

Finally, we build properties about combining colorings of
neighborhoods together. We can combine them individually to reform the
entire graph. In particular, we want to use this fact to show that the
partial colorings of neighborhoods will form a valid coloring when
combined together. We can show this works for any two disjoint partial
colorings and apply induction for the whole process.

** Phase II Lemmas
In Phase II, we color a graph with maximum degree $d$ with $d+1$
colors.  The coloring proceeds by repeatedly selecting and removing
vertices of highest degree in the graph, then coloring them all the
same, then we proceed with the next highest degree until there are no
more uncolored vertices.  Thus, we have to prove that process of
selecting highest degree vertices (while removing them) never selects
adjacent vertices. The following statement captures this:

#+BEGIN_SRC coq
Lemma remove_max_deg_adj : forall (g : graph) (i j : node) (d : nat),
    (d > 0) ->
    undirected g ->
    no_selfloop g ->
    max_deg g = d ->
    M.In i g ->
    M.In j g ->
    degree g j = d ->
    degree (remove_node i g) j = d ->
    ~ (S.In j (adj g i)).
#+END_SRC

We then show that this holds even after repeated removals.

# continue proofreading from here

* Implementing Wigderson's algorithm
We have described the phases of the algorithm in pseudocode, but we
now must translate this into Coq. We will do this in a manner
corresponding to our lemmas. We will apply these lemmas to our
functions to prove correctness and robustness.

** Phase I
We postulate the existence of a 2-coloring function that takes a graph
$g$, a vertex $v$, two colors $c_1$ and $c_2$, and assigns a
2-coloring to the neighborhood of $v$, or fails. Note that the
function would not take any proof information. We would have to
separately prove that if the coloring failed, then it would imply the
neighborhood of $v$ is not 2-colorable.

#+BEGIN_SRC coq
Definition two_color_nbd (g : graph) (v : node) (c1 c2 : E.t) : option coloring.
Admitted.
#+END_SRC

The following theorem states the completeness of the 2-coloring
algorithm with distinct colors $c_1, c_2$ on a neighborhood of a
vertex $v$ if there existed some coloring $m$ such that the vertex was
assigned some distinct color $c_3$ while $m$ completely colored the
rest of the graph. Note that we are not able to actually ``look
inside'' the definition of $m$, merely the proof that it exists.

#+BEGIN_SRC coq
Lemma two_color_nbd_complete : forall (g : graph) (v : node) c1 c2 c3,
    c1 <> c2 ->
    c1 <> c3 ->
    c2 <> c3 ->
    no_selfloop g ->
    undirected g ->
    M.In v g ->
    (exists m, M.find v m = Some c3 /\
    coloring_complete (SP.of_list [c1;c2;c3]) g m) ->
    coloring_complete (SP.of_list [c1;c2])
                      (subgraph_of g (nodes (neighborhood g v)))
                      (two_color_nbd g v c1 c2).
#+END_SRC

** Phase II
We fully define the second phase of the algorithm. First we write a
function to iteratively extract a vertex of a given degree and remove
it from a graph. Separately, we also prove that if the degree d that
was given is the max degree, then ~extract_vertices_deg~ exhausts all
the vertices of max degree, and the graph returned has a maximum
degree of one less. Here, we have to provide a proof of termination
using the ~measure~ keyword in Coq, since Coq does not allow
non-terminating functions. We use the fact that the size of the graph
is decreasing at each step.

#+BEGIN_SRC coq
Function extract_vertices_deg (g : graph) (d : nat) {measure M.cardinal g}
    : list (node * graph) * graph :=
  match extract_deg_vert_dec g d with
  | inl v =>
      let (l, g') := extract_vertices_deg (remove_node (`v) g) d in
      ((`v, g') :: l, g')
  | inr _ => (nil, g)
  end.

Function phase2 (g : graph) {measure max_deg g} : coloring * graph :=
  match max_deg g with
  | 0 => (constant_color (nodes g) 1, (@M.empty _))
  | S n => let (ns, g') := extract_vertices_deg g (S n) in
          let ns' := SP.of_list (map fst ns) in
          let (f', g'') := phase2 g' in
          (Munion (constant_color ns' (Pos.of_nat (S n))) f', g'')
  end.
#+END_SRC

We provide a summary of the development statistics in the following
table.

#+CAPTION: Statistics of our graph theory development.
| *Filename*    | *Blank lines* | *Comment lines* | *Code lines* |
|-------------+-------------+---------------+------------|
| ~subgraph.v~  |         138 |           131 |       1145 |
| ~coloring.v~  |          80 |           146 |        994 |
| ~graph.v~     |         122 |           173 |        407 |
| ~wigderson.v~ |          47 |           119 |        228 |
| ~restrict.v~  |          14 |             6 |        181 |
| ~munion.v~    |           6 |             6 |         63 |
|-------------+-------------+---------------+------------|
| *Total*       |         407 |           581 |       3018 |
#+TBLFM: @>$2=vsum(@I..@II)::@>$3=vsum(@I..@II)::@>$4=vsum(@I..@II)

\newpage

* Survey of graph theory developments in Coq
In this section, we provide a comprehensive survey of the formal
theory of graphs in Coq, along with other work, examining their
motivations, theoretical design choices, and the robustness of their
conclusions.

** Mathematical Components
The Mathematical Components library\cite{mathcomp} in Coq is a library
of formalized mathematics in Coq. The theory spans data structures
such as numbers, lists, and finite sets to results in algebra,
topology, and analysis. In addition, the library serves as the
underlying infrastructure for machine-checked proofs of the Four Color
Theorem and Odd Order Theorem. In contrast to many developments in
Coq, and indeed many libraries built into Coq itself, the Mathematical
Components library heavily employs the proof by reflection technique
to improve efficiency and automation in formal proofs.

Proof by reflection is a technique in which the proof of a goal is
turned into a computation that can be executed by the proof assistant
itself, rather than explicitly using propositional reasoning and
constructing large proof terms. To ensure that computations properly
``reflect'' into propositional evidence, there are corresponding
soundness and completeness theorems.  It is particularly well-suited
for goals that can be reduced to a finite search space or a decidable
problem. By encoding the problem as a computationally-checkable
predicate, Coq can verify the correctness of the predicate by running
a computation that produces a certificate (i.e., evidence) of the
proof.

In the context of the Four Color Theorem\cite{gonthier}, proof by
reflection is employed in various parts of the proof, such as checking
the colorability of hypermaps, testing the validity of contract
sequences, and verifying properties of special maps. A contract
coloring and contract sequence are both concepts used when dealing
with reducible configurations for the main proof. The Four Color
Theorem states that any map on a plane or a sphere can be colored with
at most four colors such that no two adjacent regions have the same
color. In the proof of the theorem, hypermaps are used to represent
the structure of maps, and contracts are a way of simplifying the
hypermaps.

** Doczkal and Pous
Doczkal and Pous present a comprehensive library for graph theory in
Coq/ssreflect, covering various notions on simple graphs, directed
graphs, and multigraphs.\cite{doczkal} The library is the first
general-purpose graph library in Coq and provides a foundation for
formalizing results from graph theory literature, such as Menger's
theorem, the excluded-minor characterization of treewidth-two graphs,
and the correspondence between multigraphs of treewidth at most two
and terms of specific algebras.

The library offers a representation of finite graphs in Coq based on
finite types, as defined in the Mathematical Components library. This
representation includes basic notions such as paths, trees, subgraphs,
separators, and isomorphisms, as well as more advanced concepts such
as minors and treewidth, which have not been formalized previously.

Finite directed graphs (digraphs) and simple graphs are represented
using dependently typed records in Coq. A digraph is a structure
containing a finite type of vertices and a decidable (i.e., boolean)
edge relation, while a simple graph is a digraph with a symmetric and
irreflexive edge relation. Notions of paths can be defined on
digraphs, and simple graphs can inherit these notations and notions
through coercion.

One key aspect of graph theory formalization is the representation of
paths. In the library, a path is a nonempty sequence of vertices with
an edge between every pair of adjacent elements. An irredundant path
has all distinct vertices. The Mathematical Components library has
list-manipulating functions such as ~last~ that can help formalize the
notion of an xy-path in a digraph.

However, the authors found that the standard representation of paths
using lists could be cumbersome in some cases. To address this issue,
they introduced a custom data structure called ~path~, designed
specifically to represent paths in graphs. This data structure
simplifies the representation of paths, making it more convenient to
work with in formal proofs.

** CertiGraph
CertiGraph\cite{wang} is a project aimed at mechanized verification of
realistic programs that manipulate heap-represented graphs. Since many
practical problems can be abstracted as graph problems,
graph-manipulating programs are widely used. However, verifying such
programs remains challenging due to the complex nature of graphs and
their deep intrinsic sharing, which is not a typical scenario for
existing techniques from separation logic.

To address this issue, CertiGraph introduces a reusable library of
formalized graph theory that is modular and general, supporting
reasoning about abstract mathematical graphs. This library is designed
to handle various graph types, ranging from well-organized graphs with
specific properties, such as directed acyclic graphs or disjoint
forests, to totally unstructured graphs such as objects laid out in
the memory of a running program. The library formalizes key graph
theory concepts, including reachability and graph isomorphism, and
proves hundreds of theorems to support further inference.

CertiGraph utilizes separation logic to define the concrete
representation of abstract graphs in the heap. The ~Localize~ inference
rule is proposed to facilitate spatial entailments involving graphs,
generalizing the ~Ramify~ rule, and supporting existential quantifiers
in postconditions and smooth handling of modified program
variables. Several common patterns in the premises of the ~Localize~
rule are summarized, with supporting theorems to ease rule
application. The spatial representations, the ~Localize~ rule, and the
supporting theorems together form a spatial graph library.

CertiGraph is one of the most comprehensive and general developments
of graph theory in Coq for algorithmic purposes. In the development of
CertiGraph, special attention is paid to the definition of graphs to
retain as much generality as possible. The base construction of the
graph, called ~PreGraph~, is a record parameterized over types ~Vertex~
and ~Edge~, along with proofs of decidable equality over those
types. Decidable equality is considered a fundamental property for
graph-manipulating algorithms, as it is employed by almost all such
algorithms, whether explicitly realized or not.

#+begin_src coq
Definition Ensemble (U : Type) := U -> Prop.
Record PreGraph (Vertex Edge : Type)
                {EV: EqDec Vertex eq} {EE: EqDec Edge eq} := {
  vvalid : Ensemble Vertex;
  evalid : Ensemble Edge;
  src : Edge -> Vertex;
  dst : Edge -> Vertex
}.
#+end_src

Unlike the approach by Doczkal and Pous, CertiGraph's graphs are more
general as they are not restricted to finite types, allowing for
greater flexibility in handling various graph types and
graph-manipulating programs.

* Conclusion and future work
In this thesis, we have embarked on an in-depth exploration of
Wigderson's graph coloring algorithm, focusing on its formal
correctness and situating it within the broader context of graph
theory formalization in computer science and mathematics. Despite
graph theory's rich history and extensive applications, its formal
developments have often been constrained to specific use-cases or
graph definitions. To address this, we have provided a comprehensive
review of various formalization approaches found in the literature,
examining their motivations, theoretical design choices, and the
robustness of their conclusions.

Throughout this work, we have presented Wigderson's algorithm along
with our own novel formal theory of graphs that covers graph
coloring. We have proved key lemmas, leading up to a proof of
correctness of the graph coloring algorithm. Additionally, we have
reviewed various other formalizations and compared them, shedding
light on their strengths and limitations.

There are multiple avenues for future research that can extend our
work. These include finishing the verification of Wigderson's
algorithm, creating a reusable library for graph coloring, verifying
the time complexity of Wigderson's algorithm or other graph coloring
algorithms with respect to a specific cost model, and conducting
additional explorations into other areas of both finite and infinite
graph theory.

By establishing a solid foundation for the formalization of graph
theory, our work contributes to the advancement of knowledge in the
field, and opens up new opportunities for further research. We hope
that our investigation will inspire future efforts towards a more
comprehensive and rigorous understanding of graph theory and its
applications, ultimately resulting in the development of more reliable
and efficient algorithms and software systems. Furthermore, our
exploration emphasizes the value of verification in mathematics, as it
not only serves to strengthen the foundations of the discipline but
also fosters increased trust in the validity of established theorems
and proofs.

\newpage

\printbibliography[heading=bibintoc]

\newpage
* Appendix A: A formal theory of subgraphs
We fully annotate one of the main files concerning subgraphs used in
the formalization of graph theory. Every lemma shown here is fully
formalized and can be viewed online [[https://github.com/siraben/coq-wigderson/blob/3ec8b9b704199da83383c65cc68fc63126d57b77/subgraph.v][here]].

\input{subgraph-lemmas.tex}

