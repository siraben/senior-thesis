#+TITLE: Notions of graph theory in type theory
#+SUBTITLE: A case study on definitional differences between type-theoretic constructions of graphs.
#+AUTHOR: Siraphob (Ben) Phipathananunth
#+LATEX_CLASS: scrartcl
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{bussproofs}
\newcommand{\typ}{\,:\,}
\newcommand{\lam}[2]{\lambda #1.\,#2}
\newcommand{\app}[2]{#1\,#2}


#+BEGIN_comment
• Introduction
  • Historical context for logics, formalization of mathematics
• Overview of dependent type theory
  • Comparisons with set theory and first-order theories
  • Curry-Howard correspondence
  • Constructivism and axioms
  • Representation of mathematical objects in type theory
• Overview of graph theory formalizations in Coq
  • math-comp (2008), formalization of four-color theorem
  • CertiGraph (2019), verification of graph-manipulating programs
  • Doczkal and Pous (2019), formalization of Menger’s theorem and treewidths
  • my formalization, verification of graph coloring
• Conclusion
  • Relation to developments in other proof assistants (Lean, Isabelle/HOL)
• Future work

#+END_comment

* Introduction
Despite the rich theory and extensive applications of graph theory in
computer science and mathematics, formal developments of graph theory
have mostly been restricted to specific applications or definitions of
graphs. In this work we seek to catalog various approaches to
formalization of graph theory that have been taken in the literature,
in particular, the motivations underlying the formalization, the
theoretical design choices taken and the strength of the conclusions.

** Notational conventions
To maintain consistent notation throughout the paper, we will use
/italics/ when referencing mathematical objects such as sets and types.
We will use ~monospace~ when referencing definitions in the Coq proof
assistant. This is so we can remain unambiguous when we refer to a
graph /G/, its degree $|G|$ and a Coq statement ~max_degree G > 0~. that
its degree is non-zero.

* Mechanization of mathematics and computer science
# cite resources in CertiGraph thesis
The formalist approach to mathematics has had a long history dating
back to Euclid's /Elements/. In such developments, it is desirable to
capture arguments and conclusions drawn from a finite set of axioms
and rules of inference. Proof checking would then be a process that a
mathematician could follow by hand. If the axioms and inferences were
applied correctly, then that is all that is needed to establish the
validity of a result.

# https://en.wikipedia.org/wiki/Non-surveyable_proof
# cite Gonthier 2005
However, in recent years, there have been cases where some
mathematical proofs were considered infeasible for a human to verify,
thus bringing into question the validity of the result. For instance,
in 1976, Appel and Haken announced a positive proof of the four-color
problem which was assisted in part by a computer program to perform
the extensive case analysis for the reducible configurations. However,
in the years that followed, several errors were uncovered which were
subsequently fixed. Eventually, in 2005, Gonthier et al. formalized
the result in the Coq proof assistant, eliminating the need for
trusting a program to check the cases.

# cite Hales 1998
A similar series of events played out for the proof of the Kepler
Conjecture, which concerns the optimal packing density for spheres in
three dimensions. Hales (1998) announced a proof of the Kepler
conjecture involving lengthy case analysis with computer
assistance. Subsequently, with Hales leading the Flyspeck project, a
formal proof of the Kepler conjecture was announced in 2017, using the
Isabelle and HOL Light proof assistants.

# https://drops.dagstuhl.de/opus/volltexte/2021/13914/pdf/LIPIcs-ITP-2021-19.pdf
Mechanization can also provide much-needed rigor to areas that contain
many folklore results. In 2021, Forster et al. presented a mechanized
proof of the time invariance thesis for the weak call-by-value
\lambda-calculus, which states that the weak call-by-value
\lambda-calculus and Turing machines can simulate each other with a
polynomial overhead in time. Forseter et al. 2021 provide an account
of prior work on the result and the varying levels of formality in
them. The work has been contributed to the Coq Library of
Undecidability Proofs.

Inspired by these lines of work, we seek to understand, document and
develop mechanized theories of graph theory in Coq. Graph theory is a
particularly suitable area for mechanization due to its wide
applicability across various fields, its simple underlying structure,
and its computability. Graphs are fundamental objects in mathematics
and computer science, with numerous applications in physics, biology,
social sciences, and engineering. They are used to model complex
systems, such as networks of social interactions, transportation
systems, communication networks, and more.

The simplicity of graphs' underlying structure makes them a natural
fit for mechanization. Graphs consist of vertices and edges, which can
be represented as sets, functions or relations (as we shall see,
representation can bring have subtle metatheoretic implications). This
simplicity allows for a clear formalization of the concepts and
definitions of graph theory, and facilitates the automation of
reasoning tasks.

Furthermore, graph algorithms are inherently computable, making them
amenable to computer-assisted proofs. The algorithms for problems such
as finding the shortest path between two vertices, testing for the
existence of a cycle, or determining the chromatic number of a graph,
can be implemented in a computer program and executed to obtain a
solution. This computability enables the use of proof assistants,
which can help verify the correctness of the algorithms and proofs.

** Formal proof of the Four-Color Theorem
# cite 4color theorem
The arguably most well-known formalization of graph theory in a proof
assistant can be seen in Gonthier's formal proof of the Four-Color
Theorem.


# expand
In the literature, graph theory has been successfully implemented in
Coq and has lead to formalizations of major theorems such as the four
color theorem. Other results include formalization of Ramsey
theorems, max-flow min-cut for countable graphs.

# cite Graph Theory in Coq: Minors, Treewidth and Isomorphisms
Doczkal and Pous state that ...

However, many assumptions underlie the graph structure used in formal
developments. For instance, it is often assumed that the vertex type
is finite and the edge relation is decidable.

These are reasonable assumptions.

The assumptions that underlie such formal developments

** CertiGraph
# Certifying graph-manipulating C programs via localizations within
# data structures
Wang et al. develops mechanized graph theory as a necessary component
of being able to reason about graph-manipulating programs written in
CompCert C, a dialect of the C programming language that has a
verified compiler (i.e. the preservation of the semantics of the
source and compiled programs is formally stated and proved). To the
author's knowledge, this is one of the most comprehensive general
development of graph theory in Coq to date.

# cite Wang thesis: Mechanized Verification of Graph-Manipulating
# Programs
In Wang 2019, particular attention was paid to the definition of
graphs in order to retain as much generality as possible. The base
construction of the graph is as follows:

#+begin_src coq
Definition Ensemble (U : Type) := U -> Prop.
Record PreGraph (Vertex Edge : Type)
                {EV: EqDec Vertex eq} {EE: EqDec Edge eq} := {
  vvalid : Ensemble Vertex;
  evalid : Ensemble Edge;
  src : Edge -> Vertex;
  dst : Edge -> Vertex
}.
#+end_src

That is, we start with a notion of a ~PreGraph~, which is a record
parameterized over types ~Vertex~ and ~Edge~ (corresponding to the types
for vertices and edges respectively), along with proofs of decidable
equality over those types.  As we have seen in a previous section,
decidable equality for types is not guaranteed in the same way it is
for set theory.  In the context of graph-manipulating programs, Wang
states that decidable equality ``is such a fundamental property that
almost all sensible graph-manipulating algorithms employ it whether or
not they realize it''.

# continue talking about Wang's construction of graphs in type theory



* Overview of dependent type theory
Type theory has a rich history, dating back to the work of Bertrand
Russell and Alfred North Whitehead's Principia Mathematica in the
early 20th century. The aim of type theory is to provide a foundation
for mathematics that avoids the paradoxes arising from naive set
theory. In type theory, the objects of interest are not sets, but
rather types and terms over those types.

Simply Typed Lambda Calculus (STLC) is a type theory that was
introduced by Church in the 1940s. It consists of rules of inference
that declare how one may produce valid derivations. The objects of
interest in STLC are terms and types over those terms. When a term $x$
has the type $\tau$, the notational convention is $x:\tau$, which is
analogous to set membership.

Proof rules are a useful tool in STLC to establish the validity of
type derivations. Here are the inference rules for the three rules in
STLC, along with their names:

\begin{prooftree}
\AxiomC{}
\RightLabel{(Var)}
\UnaryInfC{$\Gamma,x:\tau \vdash x:\tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash e_1 : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash e_2 : \sigma$}
\RightLabel{(App)}
\BinaryInfC{$\Gamma \vdash e_1\,e_2 : \tau$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma,x:\sigma \vdash e : \tau$}
\RightLabel{(Abs)}
\UnaryInfC{$\Gamma \vdash (\lambda x.e) : \sigma \to \tau$}
\end{prooftree}

The first inference rule is for the variable rule, which states that
if $x$ has type $\tau$ in the context $\Gamma$, then $x$ has type
$\tau$. The second inference rule is for the application rule, which
states that if $e_1$ has type $\sigma \to \tau$ and $e_2$ has type
$\sigma$ in the context $\Gamma$, then $e_1\ e_2$ has type $\tau$. By
convention, application is left-associative and parentheses may be
omitted. The third inference rule is for the lambda abstraction rule,
which states that if $e$ has type $\tau$ in the context $\Gamma$
extended with a variable $x$ of type $\sigma$, then $\lambda x.e$ has
type $\sigma \to \tau$.

Polymorphic lambda calculus extends STLC by introducing type-level
quantifiers, allowing functions to be defined over types. One example
of polymorphic lambda calculus is System F, which adds the ability to
define functions over types, creating a type hierarchy. The
quantifiers in System F are type-level, allowing for more expressive
type signatures. Here is an example of an inference rule for the type
abstraction rule in System F:

\begin{prooftree}
\AxiomC{$\Gamma, \alpha \vdash e:\tau$}
\RightLabel{(TAbs)}
\UnaryInfC{$\Gamma \vdash \Lambda \alpha.e:\forall \alpha.\tau$}
\end{prooftree}

This inference rule shows that if expression $e$ has type $\tau$ in
the context $\Gamma$ extended with a type variable $\alpha$, then the
type abstraction $\Lambda \alpha.e$ has the polymorphic type $\forall
\alpha.\tau$.

Dependent type theory extends System F by allowing types to depend on
terms, enabling more expressivity. The Calculus of Constructions is an
example of dependent type theory that adds the ability to define
functions over types, creating a type hierarchy. The Calculus of
Inductive Constructions extends the Calculus of Constructions with
inductive types, allowing for formalization of mathematical structures
such as natural numbers, lists, and trees.

In the Calculus of Constructions, a key feature is the use of
universes, which are a hierarchy of types that can contain other
types. A universe is a type that can serve as the type of other types,
and universes can contain each other in a hierarchy. For example, the
universe of small types might be contained within a larger universe of
larger types.

Universes are necessary in the Calculus of Constructions because they
allow us to avoid paradoxes that arise when types are allowed to
contain themselves. By separating types into a hierarchy of universes,
we can ensure that any given type is contained in a universe that is
larger than itself, preventing paradoxes such as Russell's paradox.

Here is an example of a proof rule for the dependent product formation
rule in the Calculus of Constructions:

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \typ U_i$}
\AxiomC{$\Gamma, x:A \vdash B \typ U_j$}
\RightLabel{(Prod)}
\BinaryInfC{$\Gamma \vdash (\Pi x:A.B) \typ U_{\max(i,j)}$}
\end{prooftree}

This inference rule shows that if $A$ has type $U_i$ and $B$ has type
$U_j$ in the context $\Gamma$ extended with variable $x$ of type $A$,
then the dependent product $\Pi x:A.B$ has type $U_{\max(i,j)}$.

Dependent type theory provides a foundation for modern proof
assistants such as Coq and Lean, which use the Calculus of Inductive
Constructions as their underlying logic. These proof assistants are
used to formalize mathematics, verify software, and prove the
correctness of algorithms.

** Curry-Howard correspondence

The Curry-Howard correspondence provides a correspondence between proof calculi and computational type systems. In propositional logic, a formula consists of either a propositional variable $X_n$ or a compound formula $A \land B$, $A \lor B$, $A \implies B$, $\lnot A$, where $A$ and $B$ are formulas. The Curry-Howard correspondence provides a way to map these logical formulas to types and lambda terms in a computational type system. The table below summarizes the correspondence between logic, types, and sets.

| *Logic*                | *Types*              | *Sets*                          |
|----------------------+--------------------+-------------------------------|
| proposition          | $A$                | set                           |
| proof                | $a : A$            | element                       |
| predicate            | $B(x)$             | family of sets                |
| conditional proof    | $b(x): B(x)$       | family of elements            |
| $\bot,\top$          | 0,1                | $\emptyset,{\emptyset}$       |
| $A\lor B$            | $A + B$            | disjoint union                |
| $A\land B$           | $A \times B$       | cartesian product             |
| $A\implies B$        | $A \to B$          | set of functions              |
| $\exists_{x:A} B(x)$ | $\sum_{x:A} B(x)$  | disjoint union of families    |
| $\forall_{x:A} B(x)$ | $\prod_{x:A} B(x)$ | cartesian product of families |

For the simply-typed lambda calculus, the Curry-Howard correspondence can be viewed as a theorem that relates the derivation of any judgement $x_1:A_1,\ldots,x_n:A_n\vdash B$ with a lambda term $M$ such that $x_1:A_1,\ldots,x_n:A_n\vdash M : B$ is a valid typing judgement. In other words, each valid proof in propositional logic corresponds to a valid lambda term in the simply-typed lambda calculus, and vice versa.

** Constructing new types in type theory

In type theory, it is possible to introduce new types by either
defining them as inductive types or by defining them as dependent
types. The ability to construct new types is a fundamental aspect of
type theory that enables the encoding of complex mathematical
structures.

In the Simply-Typed Lambda Calculus (STLC), only base types and
function types can be defined. Base types are fixed by the language,
while function types are constructed using the arrow operator
$\to$. For example, the type of a function that takes an integer as
input and returns a boolean as output can be written as $int \to
bool$.

In System F, polymorphic types can be defined using universal
quantification. For example, the identity function can be defined with
type $\forall \alpha. \alpha \to \alpha$, where $\alpha$ is a type
variable ranging over all possible types. This type captures the
essence of the identity function, which takes any input of any type
and returns the same value.

In the Calculus of Constructions, new types can be defined using
dependent products, dependent sums, and inductive types. A dependent
product is a type of the form $\prod_{x:A} B(x)$, where $A$ is a type
and $B : A \to \mathbb{U}$ is a type that depends on $x$. This type
can be interpreted as the type of functions that take an input of type
$A$ and return an output of type $B(x)$ for some $x$. For example, the
dependent product $\prod_{n:\mathbb{N}}\mathbb{R}^n$ represents the
type of functions that take an input $n$ representing the dimension of
a vector and return an output of type $\mathbb{R}^n$ representing a
vector in \(n\)-dimensional space. Note that if $B : A \to \mathbb{U}$
is a constant function, the dependent product $\prod_{x:A} B(x)$ is
the same as the function type $A \to B$.

A dependent sum is a type of the form $\sum_{x:A} B(x)$, where $A$ is
a type and $B(x)$ is a type that depends on $x$. This type can be
interpreted as the type of pairs $(a,b)$ where $a$ is an element of
type $A$ and $b$ is an element of type $B(a)$. For example, the
dependent sum $\sum_{n:\mathbb{N}}\mathbb{R}^n$ represents the type of
pairs $(n,v)$ where $n$ is a natural number representing the dimension
of a vector and $v$ is an element of type $\mathbb{R}^n$ representing
a vector in \(n\)-dimensional space.

Inductive types allow for the construction of new types using
constructors that create new elements of the type. For example, the
natural numbers can be defined as an inductive type with constructors
$0$ and $succ(n)$, where $n$ is a natural number. The type of natural
numbers can be written as $Nat$, and elements of this type can be
constructed using the constructors $0$ and $succ(n)$.

** Inductive Types in the Calculus of Constructions
Inductive types are a powerful feature in the Calculus of
Constructions, enabling the definition of complex mathematical
structures such as natural numbers, lists, and trees. In Coq, one of
the most popular proof assistants based on the Calculus of
Constructions, inductive types are defined using the Inductive keyword
followed by the name of the type and its constructors.

For example, the natural numbers can be defined in Coq as follows:

#+BEGIN_SRC coq
Inductive nat : Type :=
| O : nat
| S : nat -> nat.
#+END_SRC

This definition introduces a new type nat with two constructors O and
S, representing zero and successor, respectively. The constructor S
takes an argument of type nat and returns a new nat representing its
successor.

Lists can also be defined as an inductive type in Coq, with two
constructors ~nil~ and ~cons~ representing the empty list and the cons
operation, respectively:

#+BEGIN_SRC coq
Inductive list (A : Type) : Type :=
| nil : list A
| cons : A -> list A -> list A.
#+END_SRC

This definition introduces a new type list A parameterized over a type
A, with two constructors nil and cons. The constructor cons takes an
element of type A and a list of type list A, and returns a new list
with the element added to the front.

Here is an example of a Coq function that computes the length of a list:

#+BEGIN_SRC coq
Fixpoint length {A : Type} (l : list A) : nat :=
match l with
| nil => O
| cons _ xs => S (length xs)
end.
#+END_SRC

This function uses pattern matching to match on the two constructors
nil and cons, and recursively computes the length of the rest of the
list using the length function.

In the Calculus of Constructions, inductive types are defined using a
similar syntax, with constructors specified using the \(C : T\)
notation where \(C\) is the constructor name and \(T\) is the type of
the constructor.

Here is the definition of the natural numbers as an inductive type in
the Calculus of Constructions:

*Formation Rule for* $\mathbb{N}$

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\vdash \mathbb{N} : \mathbb{U}$}
\end{prooftree}

*Introduction Rules for* $\mathbb{N}$
\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\vdash 0 : \mathbb{N}$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\vdash n : \mathbb{N}$}
\UnaryInfC{$\vdash \texttt{succ}\,n : \mathbb{N}$}
\end{prooftree}

This definition introduces a new inductive type nat with two
constructors 0 and /succ/, and is a type that belongs to the universe.

** Comparisons with Set Theory and First-order Theories
Since the early 20th century, set theory and first-order theories have
been used as foundations for mathematics. However, dependent type
theory provides several advantages over these classical
systems. Unlike in set theory, which is primarily based on the notion
of collections of elements, dependent type theory revolves around the
concept of types and their inhabitants. This allows for a more natural
way of reasoning about mathematical objects and their properties.

In first-order theories, quantifiers range over elements of a single
sort, whereas in dependent type theory, it is possible for different
quantifiers in the same formula to refer to elements of different
types. This allows for a more flexible and expressive way of
expressing mathematical concepts and reasoning about them.

In summary, dependent type theory provides a powerful foundation for
mathematics and computer science, enabling precise and expressive
reasoning about mathematical objects and their properties. It is a
foundation for modern proof assistants such as Coq, Lean, and Agda,
which are used to formalize mathematics, verify software, and prove
the correctness of algorithms.

# introduction to dep TT, history, etc.
** Interactions between axioms in dependent type theory
In particular, we must take care when adding extra assumptions in type
theory, since they may interact in subtle ways that allow for LEM to
be proven. For instance, assuming propositional extensionality and
decidable equality implies LEM:

*Lemma.* /Propositional extensionality (PropExt) and decidable equality
(DecEq) together imply LEM./

# use proof environment
*Proof.* Assume /PropExt/, that is, for all propositions $P$, $Q$,
$P\leftrightarrow Q$ implies $P=Q$. Assume /DecEq/, that is, for all
types $X$ and members $a$, $b$ of type $X$, either $a=b$ or $a\neq b$.

First we prove a small lemma that for all propositions $P$,
$P=(P=\top)$. That is, a proposition $P$ is equal to a proof of
equality between $P$ and $\top$, which has a single trivial
inhabitant. By /PropExt/, it suffices to prove
$P\leftrightarrow (P=\top)$.

$(\rightarrow)$ Assume $P$. We want to show $P=\top$. By /PropExt/,
it suffices to show $P\leftrightarrow\top$, which is trivial because
we have a proof of $P$ and the trivial proof for $\top$.

$(\leftarrow)$ Assume $P=\top$. We want to show $P$. This is trivial
since using the assumption we have to prove $\top$.

#+CAPTION: Formal Coq proof of Lemma 1.
#+BEGIN_src coq
Require Import Coq.Logic.PropExtensionality.
Definition deceq := forall (X : Type) (a b : X), a = b \/ a <> b.
Definition lem := forall (P : Prop), P \/ ~ P.

(* credit: Andrej Bauer *)
Lemma small_lemma : forall (P : Prop), P = (P = True).
Proof.
  intros P.
  apply propositional_extensionality.
  split; intros.
  - apply propositional_extensionality; firstorder.
  - rewrite H; firstorder.
Qed.

Lemma deceq_lem : deceq -> lem.
Proof.
  unfold deceq, lem.
  intros deceq P.
  rewrite (small_lemma P).
  apply deceq.
Qed.
#+END_src

** Overview of Coq
Our work takes place in a logical framework of constructive type
theory, such as that of Coq. We have the hierarchy of \textit{type
universes} and a universe of \textit{propositions}, called
\texttt{Prop}, written as $\mathbb{P}$. At the type level, we have the
unit type $\boldsymbol{1}$, the empty type $\boldsymbol 0$, function
types $A\to B$, products $A\times B$, sums $A+B$, dependent products
$\forall (x : X), F(x)$ and dependent sums $\exists (x : X),
F(x)$. Note that function application associates to the left in Coq
and every function takes one argument, so we can write $f\,a\,b$
instead of $(f(a))(b)$. For propositions, these are written as they
are in logic, $(\top,\bot,\to ,\wedge,\vee,\forall,\exists)$. For
brevity we will not go into details about the Coq type system here,
which is well-covered in literature.

An important point to make is that Coq's logic is
\textit{constructive}. In particular we do not assume excluded middle
(LEM), which is the statement $\forall (p : \mathbb{P}), p \vee \neg
p$. This is obvious in classical mathematics but since we are working
in type theory, disjunctions have to be computable (that is, we can
always find out in finite time if the disjunction is the left or the
right element. In general this does not hold in Coq (because $p$ could
be undecidable), but fortunately for us everything is pretty much
decidable (comparing integers, checking if a key is in a map or set,
etc.).

Coq consists of two languages, \textit{Gallina} and
\textit{Ltac}. Gallina is the specification language of Coq and can be
thought of as the expressions in Coq. Gallina is purely functional and
has support for dependent types and dependent pattern
matching. \textit{Ltac} is the tactic language of Coq and is what is
used to carry out formal proofs. An introduction can be found in
\cite{tactic} and \cite{hurry}. It suffices to say that, from a
usability standpoint, \textit{Ltac} commands operate on the current
\textit{proof state}, which is the context consisting of hypothesis
and a goal. The commands may introduce new hypotheses, clear existing
ones, allow application of one hypothesis to another, discriminate a
value in context, and so on.

*** Definitions in Coq

#+begin_src coq
Inductive nat : Set :=
  O : nat
| S : nat -> nat.
#+end_src

* Building graph theory in Coq
When building any mathematical theory, one must start with the
definition of the objects of that theory.

- graph theory is usually built on top of set theory
- but we're in type theory
- example of decidable equality

** Example lemma: maximum degree and subgraphs
To illustrate the level of detail that is required in a formal proof
and to motivate introspection into implicit assumptions about graphs,
we will deconstruct a lemma about how maximum degrees interact with
the subgraph relation.

*Lemma.* Let ~G'~ be a subgraph of ~G~. Then ~max_deg G' <= max_deg G~.

*Proof.* When ~max_deg G'~ is zero, this is immediate. Otherwise, there is
some vertex ~k~ of non-zero maximum degree in ~G'~. Since ~G'~ is a subgraph
of ~G~, this vertex ~k~ is also in ~G~. Since ~G'~ is a subgraph of ~G~, the
pointwise vertex sets of ~G'~ are subsets of the corresponding vertex
set in ~G~. In particular, ~G'[k]~ is a subset of ~G[k]~. Let ~t~ be the
vertex of (non-zero) maximum degree in ~G~. Since ~t~ is a vertex of
maximum degree, the size of ~G[t]~ bounds the size of all other vertex
sets, in particular ~G[k]~. Thus, ~max_deg G' = G'[k] <= G[k] <= G[t] =
max_deg G~, as desired.

* References
# turn into bibtex


- Graph Theory in Coq: Minors, Treewidth, and Isomorphisms
 https://hal.science/hal-02127698/document
- Five stages of accepting constructive mathematics https://www.ams.org/journals/bull/2017-54-03/S0273-0979-2016-01556-4/S0273-0979-2016-01556-4.pdf
- https://www.comp.nus.edu.sg/~hobor/Teaching/SW-PhD.pdf
# @article{hales_adams_bauer_dang_harrison_hoang_kaliszyk_magron_mclaughlin_nguyen_et al._2017, title={A FORMAL PROOF OF THE KEPLER CONJECTURE}, volume={5}, DOI={10.1017/fmp.2017.1}, journal={Forum of Mathematics, Pi}, publisher={Cambridge University Press}, author={HALES, THOMAS and ADAMS, MARK and BAUER, GERTRUD and DANG, TAT DAT and HARRISON, JOHN and HOANG, LE TRUONG and KALISZYK, CEZARY and MAGRON, VICTOR and MCLAUGHLIN, SEAN and NGUYEN, TAT THANG and et al.}, year={2017}, pages={e2}}
